{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/felixkoerber/Multimodal-Integration-ABIDE/blob/main/Multimodal_Integration_for_Indentifying_Stratification_of_ASD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bL29UynvVrV8"
      },
      "outputs": [],
      "source": [
        "train=False\n",
        "yang =True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U21C3w94iMbs"
      },
      "source": [
        "# Multimodal Integration for Indentifying Stratification of ASD\n",
        "\n",
        "Code for Bachelor Thesis of Felix Körber"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDcvVH8rjZtZ"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-hKGC86q6N0b",
        "outputId": "bd2e2f23-7c40-4573-98c2-ad06cd3bd88b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-ignite\n",
            "  Downloading pytorch_ignite-0.4.13-py3-none-any.whl (272 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/272.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m235.5/272.4 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m272.4/272.4 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch<3,>=1.3 in /usr/local/lib/python3.10/dist-packages (from pytorch-ignite) (2.1.0+cu118)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pytorch-ignite) (23.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<3,>=1.3->pytorch-ignite) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch<3,>=1.3->pytorch-ignite) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<3,>=1.3->pytorch-ignite) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<3,>=1.3->pytorch-ignite) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<3,>=1.3->pytorch-ignite) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch<3,>=1.3->pytorch-ignite) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch<3,>=1.3->pytorch-ignite) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<3,>=1.3->pytorch-ignite) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<3,>=1.3->pytorch-ignite) (1.3.0)\n",
            "Installing collected packages: pytorch-ignite\n",
            "Successfully installed pytorch-ignite-0.4.13\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (0.20.1)\n",
            "Collecting torchview\n",
            "  Downloading torchview-0.2.6-py3-none-any.whl (25 kB)\n",
            "Installing collected packages: torchview\n",
            "Successfully installed torchview-0.2.6\n",
            "Collecting statannotations\n",
            "  Downloading statannotations-0.6.0-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: numpy>=1.12.1 in /usr/local/lib/python3.10/dist-packages (from statannotations) (1.23.5)\n",
            "Collecting seaborn<0.12,>=0.9.0 (from statannotations)\n",
            "  Downloading seaborn-0.11.2-py3-none-any.whl (292 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m292.8/292.8 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from statannotations) (3.7.1)\n",
            "Requirement already satisfied: pandas<2.0.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from statannotations) (1.5.3)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from statannotations) (1.11.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.2->statannotations) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.2->statannotations) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.2->statannotations) (4.44.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.2->statannotations) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.2->statannotations) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.2->statannotations) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.2->statannotations) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.2->statannotations) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.0.0,>=0.23.0->statannotations) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=2.2.2->statannotations) (1.16.0)\n",
            "Installing collected packages: seaborn, statannotations\n",
            "  Attempting uninstall: seaborn\n",
            "    Found existing installation: seaborn 0.12.2\n",
            "    Uninstalling seaborn-0.12.2:\n",
            "      Successfully uninstalled seaborn-0.12.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed seaborn-0.11.2 statannotations-0.6.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "seaborn"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tableone\n",
            "  Downloading tableone-0.8.0-py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from tableone) (3.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tableone) (1.23.5)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (from tableone) (3.1.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from tableone) (1.5.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from tableone) (1.11.3)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.10/dist-packages (from tableone) (0.14.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from tableone) (0.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->tableone) (2.1.3)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl->tableone) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->tableone) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->tableone) (2023.3.post1)\n",
            "Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from statsmodels->tableone) (0.5.3)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels->tableone) (23.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.2->statsmodels->tableone) (1.16.0)\n",
            "Installing collected packages: tableone\n",
            "Successfully installed tableone-0.8.0\n",
            "Collecting nilearn\n",
            "  Downloading nilearn-0.10.2-py3-none-any.whl (10.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from nilearn) (1.3.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nilearn) (4.9.3)\n",
            "Requirement already satisfied: nibabel>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from nilearn) (4.0.2)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from nilearn) (1.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from nilearn) (23.2)\n",
            "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from nilearn) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.25.0 in /usr/local/lib/python3.10/dist-packages (from nilearn) (2.31.0)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from nilearn) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from nilearn) (1.11.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nibabel>=3.2.0->nilearn) (67.7.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->nilearn) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->nilearn) (2023.3.post1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25.0->nilearn) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25.0->nilearn) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25.0->nilearn) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25.0->nilearn) (2023.7.22)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->nilearn) (3.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=1.1.5->nilearn) (1.16.0)\n",
            "Installing collected packages: nilearn\n",
            "Successfully installed nilearn-0.10.2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pexpect/popen_spawn.py:60: DeprecationWarning: setDaemon() is deprecated, set the daemon attribute instead\n",
            "  self._read_thread.setDaemon(True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "## Torch\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.utils.data\n",
        "from torch import nn,optim\n",
        "from torch.autograd import Variable\n",
        "\n",
        "try:\n",
        "  from ignite.engine import Engine, Events\n",
        "  from ignite.handlers import EarlyStopping\n",
        "except:\n",
        "  !pip install pytorch-ignite\n",
        "  from ignite.engine import Engine, Events\n",
        "  from ignite.handlers import EarlyStopping\n",
        "\n",
        "## Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import axes3d\n",
        "from matplotlib import cm\n",
        "import seaborn as sns\n",
        "!pip install graphviz\n",
        "!pip install torchview\n",
        "from torchview import draw_graph\n",
        "import graphviz\n",
        "graphviz.set_jupyter_format('png')\n",
        "!pip install statannotations\n",
        "from statannotations.Annotator import Annotator\n",
        "\n",
        "# Data Handling\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "#scikit\n",
        "from yellowbrick.cluster import KElbowVisualizer\n",
        "from yellowbrick.style.palettes import PALETTES, SEQUENCES, color_palette\n",
        "from yellowbrick.style import set_palette\n",
        "\n",
        "#sklearn\n",
        "from sklearn.metrics.cluster import rand_score\n",
        "from sklearn.neighbors import KDTree\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.model_selection import StratifiedKFold, permutation_test_score\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Import tableone\n",
        "try:\n",
        "    from tableone import TableOne, load_dataset\n",
        "except (ModuleNotFoundError, ImportError):\n",
        "    # install on Colab\n",
        "    !pip install tableone\n",
        "    from tableone import TableOne, load_dataset\n",
        "\n",
        "#scipy\n",
        "from scipy import spatial\n",
        "from scipy import stats\n",
        "from scipy.stats import kendalltau, pearsonr, permutation_test,bootstrap, norm\n",
        "\n",
        "#nilearn\n",
        "!pip install nilearn\n",
        "import nilearn\n",
        "from nilearn import datasets\n",
        "from nilearn import plotting\n",
        "\n",
        "\n",
        "import warnings\n",
        "\n",
        "import plotly.graph_objects as go\n",
        "from operator import ifloordiv\n",
        "\n",
        "# Misc\n",
        "\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import os\n",
        "import sys\n",
        "import imageio\n",
        "\n",
        "import argparse\n",
        "# Link Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2DQZ-fcjxJ2"
      },
      "source": [
        "Set Up GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGQTYUvSjw0L",
        "outputId": "e149e0f9-dc0c-4054-9996-39da2bee2990"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-JHL2mAjwGk"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUBrTu2Vk3gO"
      },
      "source": [
        "# Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oukdi9J9k64r",
        "outputId": "4c22e766-f600-4bf4-a559-73f780bd2472"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "#@title\n",
        "\n",
        "# adapted from pytorch/examples/vae and ethanluoyc/pytorch-vae\n",
        "\n",
        "\n",
        "class FC_VAE(nn.Module):\n",
        "    \"\"\"Fully connected variational Autoencoder\"\"\"\n",
        "    def __init__(self, n_input, nz, n_hidden=1024):\n",
        "        super(FC_VAE, self).__init__()\n",
        "        self.nz = nz\n",
        "        self.n_input = n_input\n",
        "        self.n_hidden = n_hidden\n",
        "\n",
        "        self.encoder = nn.Sequential(nn.Linear(n_input, n_hidden*5),\n",
        "                                nn.ReLU(inplace=True),\n",
        "                                nn.BatchNorm1d(n_hidden*5),\n",
        "\n",
        "                                nn.Linear(n_hidden*5, n_hidden*2),\n",
        "                                nn.ReLU(inplace=True),\n",
        "                                nn.BatchNorm1d(n_hidden*2),\n",
        "\n",
        "                                nn.Linear(n_hidden*2, n_hidden),\n",
        "                                nn.ReLU(inplace=True),\n",
        "                                nn.BatchNorm1d(n_hidden),\n",
        "\n",
        "                                nn.Linear(n_hidden, n_hidden),\n",
        "                                nn.ReLU(inplace=True),\n",
        "                                nn.BatchNorm1d(n_hidden),\n",
        "\n",
        "                                nn.Linear(n_hidden, n_hidden),\n",
        "                                nn.ReLU(inplace=True),\n",
        "                                nn.BatchNorm1d(n_hidden),\n",
        "                                nn.Linear(n_hidden, n_hidden),\n",
        "                                )\n",
        "\n",
        "        self.fc1 = nn.Linear(n_hidden, nz)\n",
        "        self.fc2 = nn.Linear(n_hidden, nz)\n",
        "\n",
        "        self.decoder = nn.Sequential(nn.Linear(nz, n_hidden),\n",
        "                                     nn.ReLU(inplace=True),\n",
        "                                     nn.BatchNorm1d(n_hidden),\n",
        "\n",
        "                                     nn.Linear(n_hidden, n_hidden),\n",
        "                                     nn.ReLU(inplace=True),\n",
        "                                     nn.BatchNorm1d(n_hidden),\n",
        "\n",
        "                                     nn.Linear(n_hidden, n_hidden),\n",
        "                                     nn.BatchNorm1d(n_hidden),\n",
        "                                     nn.ReLU(inplace=True),\n",
        "\n",
        "\n",
        "                                     nn.Linear(n_hidden, n_hidden*2),\n",
        "                                     nn.ReLU(inplace=True),\n",
        "                                     nn.BatchNorm1d(n_hidden*2),\n",
        "\n",
        "                                     nn.Linear(n_hidden*2, n_hidden*5),\n",
        "                                     nn.ReLU(inplace=True),\n",
        "                                     nn.BatchNorm1d(n_hidden*5),\n",
        "                                     nn.Linear(n_hidden*5, n_input),\n",
        "                                    )\n",
        "    def forward(self, x):\n",
        "        mu, logvar = self.encode(x)\n",
        "        z = self.reparametrize(mu, logvar)\n",
        "        res = self.decode(z)\n",
        "        return res, z, mu, logvar\n",
        "\n",
        "    def encode(self, x):\n",
        "        h = self.encoder(x)\n",
        "        return self.fc1(h), self.fc2(h)\n",
        "\n",
        "    def reparametrize(self, mu, logvar):\n",
        "        std = logvar.mul(0.5).exp_()\n",
        "        if torch.cuda.is_available():\n",
        "            eps = torch.cuda.FloatTensor(std.size()).normal_()\n",
        "        else:\n",
        "            eps = torch.FloatTensor(std.size()).normal_()\n",
        "        eps = Variable(eps)\n",
        "        return eps.mul(std).add_(mu)\n",
        "\n",
        "    def decode(self, z):\n",
        "        return self.decoder(z)\n",
        "\n",
        "    def get_latent_var(self, x):\n",
        "        mu, logvar = self.encode(x)\n",
        "        z = self.reparametrize(mu, logvar)\n",
        "        return z\n",
        "\n",
        "    def generate(self, z):\n",
        "        res = self.decode(z)\n",
        "        return res\n",
        "\n",
        "\n",
        "\n",
        "class FC_Classifier(nn.Module):\n",
        "    \"\"\"Latent space discriminator\"\"\"\n",
        "    def __init__(self, nz, n_hidden=512, n_out=3):\n",
        "        super(FC_Classifier, self).__init__()\n",
        "        self.nz = nz\n",
        "        self.n_hidden = n_hidden\n",
        "        self.n_out = n_out\n",
        "\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(nz, n_hidden),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(n_hidden, n_hidden),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(n_hidden, n_hidden),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(n_hidden, n_hidden),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(n_hidden, n_hidden),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(n_hidden,n_out)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class Simple_Classifier(nn.Module):\n",
        "    \"\"\"Latent space discriminator\"\"\"\n",
        "    def __init__(self, nz, n_out=3):\n",
        "        super(Simple_Classifier, self).__init__()\n",
        "        self.nz = nz\n",
        "        self.n_out = n_out\n",
        "\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(nz, n_out),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kf-WLMrloGpN"
      },
      "source": [
        "# Arguments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KYM02M8oJUf",
        "outputId": "dab41da8-ceaf-46bb-ee73-2c222360495a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "# parse arguments\n",
        "class setup_args():\n",
        "\n",
        "    batch_size=32\n",
        "    max_epochs=300\n",
        "    nz=512\n",
        "    lamb=0.0000001 #beta weight\n",
        "    alpha =.1\n",
        "    dist_factor =1\n",
        "    learning_rate_D = 1e-4\n",
        "    learning_rate_AE =1e-4\n",
        "    weight_decay=0\n",
        "    n_hidden=512\n",
        "    save_freq=10\n",
        "\n",
        "args = setup_args()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKIehI7IdGua"
      },
      "source": [
        "# Set-Up Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VL9h98WZh5PU",
        "outputId": "cd69a164-fad5-4e2d-e867-2e0fcb367cf6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "### Dataloader\n",
        "class Combined_Dataset_Train():\n",
        "    def __init__(self):\n",
        "        isfunc=np.load(\"/content/drive/My Drive/BA/isfunc.npy\", allow_pickle=True)\n",
        "        #Pheno Data\n",
        "        pheno_data=pd.read_csv('/content/drive/My Drive/BA/pheno_data.csv', index_col=0)\n",
        "        pheno_data.iloc[isfunc==1]\n",
        "\n",
        "        #Functional Data\n",
        "        func_data= np.load(\"/content/drive/My Drive/BA/func_flat_Tal_new.npy\", allow_pickle=True)\n",
        "        func_data[np.where(np.isnan(func_data))]=0\n",
        "        func_data= (func_data - np.mean(func_data)) / np.std(func_data)\n",
        "\n",
        "        #Area Data\n",
        "        area_data=np.load('/content/drive/My Drive/BA/area_data_red.npy')[:,:,0].T\n",
        "        area_data=(area_data - np.mean(area_data)) / np.std(area_data)\n",
        "        area_data=area_data[isfunc==1]\n",
        "        #Cortical Thickness Data\n",
        "        thick_data=np.load('/content/drive/My Drive/BA/thick_data_red.npy')[:,:,0].T\n",
        "        thick_data=(thick_data - np.mean(thick_data)) / np.std(thick_data)\n",
        "        thick_data=thick_data[isfunc==1]\n",
        "\n",
        "        self.label = pheno_data.iloc             [isfunc==1]\n",
        "        self.func_data = func_data              [:]\n",
        "        self.area_data =area_data               [:]\n",
        "        self.thick_data =thick_data             [:]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.label)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return torch.tensor(self.func_data[idx,:]).float(),torch.tensor(self.area_data[idx,:]).float(),torch.tensor(self.thick_data[idx,:]).float(),torch.tensor(self.label.iloc[idx,6]-1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-mpYm7wdJ9u"
      },
      "source": [
        "# Initiate Dataloader and Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oOIqRL_75wSw",
        "outputId": "6dd8ef88-e675-459e-c715-6ac933b691cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded\n"
          ]
        }
      ],
      "source": [
        "# retrieve dataloader\n",
        "\n",
        "# Define the train and test dataloaders\n",
        "dataset_Train = (Combined_Dataset_Train())\n",
        "train_dataloader = DataLoader(dataset_Train, batch_size=args.batch_size, drop_last=False, shuffle=True)\n",
        "\n",
        "dataset_Test = (Combined_Dataset_Train())\n",
        "test_dataloader = DataLoader(dataset_Test, batch_size=args.batch_size,drop_last=False, shuffle=False)\n",
        "\n",
        "print('Data loaded')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXfeBhaRjlw-",
        "outputId": "62996692-096f-44e0-c705-8f84e5ee3b70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#============= TRAINING INITIALIZATION ==============\n",
        "\n",
        "# initialize autoencoder\n",
        "model_func = FC_VAE  (n_input=4656,    nz=args.nz,n_hidden=args.n_hidden).to(device)\n",
        "model_thick = FC_VAE (n_input=163842,  nz=args.nz,n_hidden=args.n_hidden).to(device)\n",
        "model_area = FC_VAE  (n_input=163842,  nz=args.nz,n_hidden=args.n_hidden).to(device)\n",
        "netClf = FC_Classifier(nz=args.nz).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63faGTdUvnzn",
        "outputId": "30aae0b2-c9da-4e5a-b033-386f8affc195"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "# setup optimizer\n",
        "\n",
        "opt_netthick  = torch.optim.Adam(params=model_thick.parameters (), lr=args.learning_rate_AE)\n",
        "opt_netarea   = torch.optim.Adam(params=model_area.parameters  (), lr=args.learning_rate_AE)\n",
        "opt_netfunc   = torch.optim.Adam(params=model_func.parameters  (), lr=args.learning_rate_AE)\n",
        "opt_netClf    = torch.optim.Adam(params=netClf.parameters      (), lr=args.learning_rate_D)\n",
        "\n",
        "# loss criteria\n",
        "criterion_reconstruct = nn.MSELoss()\n",
        "criterion_classify    = nn.CrossEntropyLoss()\n",
        "criterion_latent_dis  = nn.L1Loss()\n",
        "\n",
        "criterion_reconstruct = criterion_reconstruct.to(device)\n",
        "criterion_classify    = criterion_classify.to(device)\n",
        "criterion_latent_dis    = criterion_latent_dis.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BT1xQUfVdDCx"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I35amxs56Qv3",
        "outputId": "37407c2d-bd15-4079-dd70-9e0bdf481be2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "def compute_KL_loss(mu, logvar):\n",
        "    if args.lamb>0:\n",
        "        KLloss = -0.5*torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "        return args.lamb * KLloss\n",
        "    return 0\n",
        "\n",
        "def train_autoencoders(func_inputs, area_inputs, thick_inputs,labels):\n",
        "    model_thick.train()\n",
        "    model_area.train()\n",
        "    model_func.train()\n",
        "    netClf.eval()\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "      thick_inputs, area_inputs,func_inputs = thick_inputs.to(device), area_inputs.to(device),func_inputs.to(device)\n",
        "      labels=labels.to(device)\n",
        "\n",
        "    # forward pass\n",
        "    thick_recon, thick_latents,thick_mu, thick_logvar = model_thick(thick_inputs)\n",
        "    area_recon, area_latents, area_mu, area_logvar = model_area(area_inputs)\n",
        "    func_recon, func_latents,func_mu, func_logvar = model_func(func_inputs)\n",
        "\n",
        "    thick_to_area=model_area.decode(thick_latents)\n",
        "    thick_to_func=model_func.decode(thick_latents)\n",
        "\n",
        "    area_to_thick=model_thick.decode(area_latents)\n",
        "    area_to_func=model_func.decode(area_latents)\n",
        "\n",
        "    func_to_thick=model_thick.decode(func_latents)\n",
        "    func_to_area=model_area.decode(area_latents)\n",
        "\n",
        "    thick_scores = netClf(thick_latents)\n",
        "    area_scores = netClf(area_latents)\n",
        "    func_scores = netClf(func_latents)\n",
        "\n",
        "\n",
        "    thick_labels = torch.zeros  (thick_scores.size(0),).long()\n",
        "    area_labels  = torch.zeros(area_scores.size (0),).long()\n",
        "    func_labels  = torch.zeros (func_scores.size(0),).long()\n",
        "\n",
        "    thick_labels[:]= 0\n",
        "    area_labels [:]= 1\n",
        "    func_labels [:]= 2\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        thick_labels, area_labels,func_labels = thick_labels.to(device), area_labels.to(device),func_labels.to(device)\n",
        "\n",
        "\n",
        "    # compute recon losses\n",
        "    thick_recon_loss = criterion_reconstruct(thick_inputs, thick_recon)\n",
        "    area_recon_loss = criterion_reconstruct(area_inputs, area_recon)\n",
        "    func_recon_loss = criterion_reconstruct(func_inputs, func_recon)\n",
        "\n",
        "\n",
        "    distances_metric =  (1/3)*criterion_latent_dis(func_latents,thick_latents) +   (1/3)*criterion_latent_dis(func_latents,area_latents)+(1/3)*criterion_latent_dis(thick_latents,area_latents)\n",
        "    distances_metric = args.dist_factor*distances_metric\n",
        "\n",
        "    # compute cross modal latent recon losses\n",
        "    cmrl_ttoa= criterion_reconstruct(area_inputs, thick_to_area)\n",
        "    cmrl_ttof= criterion_reconstruct(func_inputs, thick_to_func)\n",
        "\n",
        "    cmrl_atot= criterion_reconstruct(thick_inputs, area_to_thick)\n",
        "    cmrl_atof= criterion_reconstruct(func_inputs, area_to_func)\n",
        "\n",
        "    cmrl_ftot= criterion_reconstruct(thick_inputs, func_to_thick)\n",
        "    cmrl_ftoa= criterion_reconstruct(area_inputs, func_to_area)\n",
        "\n",
        "    cmrl = (cmrl_ttoa+cmrl_ttof+cmrl_atot+cmrl_atof+cmrl_ftot+cmrl_ftoa)/6\n",
        "\n",
        "    # compute crossmodal loss\n",
        "\n",
        "    kl_loss = compute_KL_loss(thick_mu, thick_logvar) + compute_KL_loss(area_mu, area_logvar)+compute_KL_loss(func_mu,func_logvar)\n",
        "    clf_loss =  (1/6) * criterion_classify(thick_scores, area_labels) +  \\\n",
        "      (1/6) * criterion_classify(thick_scores, func_labels) +(1/6) * criterion_classify(area_scores, func_labels) + \\\n",
        "      (1/6)* criterion_classify(area_scores, thick_labels) +  (1/6) * criterion_classify(func_scores, area_labels) +  (1/6) * criterion_classify(func_scores, thick_labels)\n",
        "    #clf_loss = (1/3)*criterion_classify(thick_scores, thick_labels) + (1/3)* criterion_classify(area_scores, area_labels) + (1/3)* criterion_classify(func_scores, func_labels)\n",
        "    loss = thick_recon_loss + area_recon_loss + func_recon_loss+ kl_loss   +  clf_loss +distances_metric + cmrl\n",
        "\n",
        "\n",
        "    # reset parameter gradients\n",
        "    opt_netthick.zero_grad()\n",
        "    opt_netarea.zero_grad()\n",
        "    opt_netfunc.zero_grad()\n",
        "\n",
        "    # backpropagate and update model\n",
        "    loss.backward()\n",
        "\n",
        "    opt_netthick.step()\n",
        "    opt_netarea.step()\n",
        "    opt_netfunc.step()\n",
        "\n",
        "    #Validation Loss\n",
        "    summary_stats = {'loss': loss,'thick_recon_loss': thick_recon_loss*thick_scores.size(0), 'area_recon_loss': area_recon_loss*area_scores.size(0),\n",
        "                     'func_recon_loss': func_recon_loss*func_scores.size(0),'clf_loss': clf_loss*(thick_scores.size(0)+area_scores.size(0)+func_scores.size(0)),\n",
        "                      'cmr_loss':cmrl*(thick_scores.size(0)+area_scores.size(0)+func_scores.size(0)),\n",
        "                      'KL_loss':kl_loss,'distances_metric':distances_metric*(thick_scores.size(0)+area_scores.size(0)+func_scores.size(0))\n",
        "                      }\n",
        "\n",
        "    return summary_stats\n",
        "\n",
        "def train_classifier(func_inputs,area_inputs,thick_inputs):\n",
        "\n",
        "    model_thick.eval()\n",
        "    model_area.eval()\n",
        "    model_func.eval()\n",
        "    netClf.train()\n",
        "\n",
        "    # process input data\n",
        "    if torch.cuda.is_available():\n",
        "      thick_inputs, area_inputs,func_inputs = thick_inputs.to(device), area_inputs.to(device),func_inputs.to(device)\n",
        "\n",
        "\n",
        "    # forward pass\n",
        "    _, thick_latents, _, _  = model_thick(thick_inputs)\n",
        "    _, area_latents, _, _   = model_area(area_inputs)\n",
        "    _, func_latents, _, _   = model_func(func_inputs)\n",
        "\n",
        "    thick_scores  = netClf(thick_latents)\n",
        "    area_scores   = netClf(area_latents)\n",
        "    func_scores   = netClf(func_latents)\n",
        "\n",
        "    thick_labels = torch.zeros  (thick_scores.size(0),).long()\n",
        "    area_labels  = torch.zeros(area_scores.size (0),).long()\n",
        "    func_labels  = torch.zeros (func_scores.size(0),).long()\n",
        "\n",
        "    thick_labels[:]= 0\n",
        "    area_labels [:]= 1\n",
        "    func_labels [:]= 2\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        thick_labels, area_labels,func_labels = thick_labels.to(device), area_labels.to(device),func_labels.to(device)\n",
        "\n",
        "    clf_loss = (1/3)*criterion_classify(thick_scores, thick_labels) + (1/3)* criterion_classify(area_scores, area_labels) + (1/3)* criterion_classify(func_scores, func_labels)\n",
        "    loss = clf_loss\n",
        "\n",
        "\n",
        "    # backpropagate and update model\n",
        "    opt_netClf.zero_grad()\n",
        "    loss.backward()\n",
        "    opt_netClf.step()\n",
        "    summary_stats = {'clf_loss': clf_loss*(thick_scores.size(0)+area_scores.size(0)+area_scores.size(0)),\n",
        "                     'thick_n_samples': thick_scores.size(0),'area_n_samples': area_scores.size(0),\n",
        "                     'func_n_samples':func_scores.size(0)}\n",
        "\n",
        "    return summary_stats\n",
        "\n",
        "def accuracy(output, target):\n",
        "    c=output.cpu().detach().numpy()\n",
        "    target=target.cpu().detach().numpy()\n",
        "    c[np.where(c>0.5)]=1\n",
        "    c[np.where(c<0.5)]=0\n",
        "    list=0\n",
        "    for i,j in zip(c,target):\n",
        "      if i==j:\n",
        "        list+=1\n",
        "    acc=list/len(target)\n",
        "    #print(acc, list)\n",
        "    return(acc)\n",
        "\n",
        "\n",
        "def mean_loss(input):\n",
        "  mean=criterion_reconstruct(input,torch.mean(input))\n",
        "  return mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxACEt-DzJFC",
        "outputId": "c7967295-3599-45a4-839f-06c1d4efd808"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([32, 4656])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([32, 163842])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 4656]) torch.Size([32, 163842]) torch.Size([32, 163842]) torch.Size([32])\n",
            "torch.Size([32, 4656]) torch.Size([32, 163842]) torch.Size([32, 163842]) torch.Size([32])\n",
            "torch.Size([32, 4656]) torch.Size([32, 163842]) torch.Size([32, 163842]) torch.Size([32])\n",
            "torch.Size([32, 4656]) torch.Size([32, 163842]) torch.Size([32, 163842]) torch.Size([32])\n",
            "torch.Size([32, 4656]) torch.Size([32, 163842]) torch.Size([32, 163842]) torch.Size([32])\n",
            "torch.Size([32, 4656]) torch.Size([32, 163842]) torch.Size([32, 163842]) torch.Size([32])\n",
            "torch.Size([32, 4656]) torch.Size([32, 163842]) torch.Size([32, 163842]) torch.Size([32])\n",
            "torch.Size([32, 4656]) torch.Size([32, 163842]) torch.Size([32, 163842]) torch.Size([32])\n",
            "torch.Size([32, 4656]) torch.Size([32, 163842]) torch.Size([32, 163842]) torch.Size([32])\n",
            "torch.Size([32, 4656]) torch.Size([32, 163842]) torch.Size([32, 163842]) torch.Size([32])\n",
            "torch.Size([32, 4656]) torch.Size([32, 163842]) torch.Size([32, 163842]) torch.Size([32])\n",
            "torch.Size([32, 4656]) torch.Size([32, 163842]) torch.Size([32, 163842]) torch.Size([32])\n",
            "torch.Size([32, 4656]) torch.Size([32, 163842]) torch.Size([32, 163842]) torch.Size([32])\n",
            "torch.Size([32, 4656]) torch.Size([32, 163842]) torch.Size([32, 163842]) torch.Size([32])\n",
            "torch.Size([32, 4656]) torch.Size([32, 163842]) torch.Size([32, 163842]) torch.Size([32])\n",
            "torch.Size([32, 4656]) torch.Size([32, 163842]) torch.Size([32, 163842]) torch.Size([32])\n",
            "torch.Size([32, 4656]) torch.Size([32, 163842]) torch.Size([32, 163842]) torch.Size([32])\n",
            "torch.Size([32, 4656]) torch.Size([32, 163842]) torch.Size([32, 163842]) torch.Size([32])\n",
            "torch.Size([32, 4656]) torch.Size([32, 163842]) torch.Size([32, 163842]) torch.Size([32])\n",
            "torch.Size([32, 4656]) torch.Size([32, 163842]) torch.Size([32, 163842]) torch.Size([32])\n",
            "torch.Size([32, 4656]) torch.Size([32, 163842]) torch.Size([32, 163842]) torch.Size([32])\n",
            "torch.Size([32, 4656]) torch.Size([32, 163842]) torch.Size([32, 163842]) torch.Size([32])\n",
            "torch.Size([32, 4656]) torch.Size([32, 163842]) torch.Size([32, 163842]) torch.Size([32])\n",
            "torch.Size([32, 4656]) torch.Size([32, 163842]) torch.Size([32, 163842]) torch.Size([32])\n",
            "torch.Size([32, 4656]) torch.Size([32, 163842]) torch.Size([32, 163842]) torch.Size([32])\n",
            "torch.Size([32, 4656]) torch.Size([32, 163842]) torch.Size([32, 163842]) torch.Size([32])\n",
            "torch.Size([32, 4656]) torch.Size([32, 163842]) torch.Size([32, 163842]) torch.Size([32])\n",
            "torch.Size([19, 4656]) torch.Size([19, 163842]) torch.Size([19, 163842]) torch.Size([19])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([19, 4656])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([19, 163842])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        }
      ],
      "source": [
        "mean_func        = 0\n",
        "mean_thick       = 0\n",
        "mean_area        = 0\n",
        "for idx, (sample) in enumerate(train_dataloader):\n",
        "\n",
        "  func_inputs   = sample[0]\n",
        "  area_inputs   = sample[1]\n",
        "  thick_inputs  = sample[2]\n",
        "  labels        = sample[3]\n",
        "  print(func_inputs.shape,area_inputs.shape,thick_inputs.shape,labels.shape)\n",
        "  mean_func     +=mean_loss(func_inputs)\n",
        "  mean_area     +=mean_loss(area_inputs)\n",
        "  mean_thick    +=mean_loss(thick_inputs)\n",
        "mean_func /= 883\n",
        "mean_area /= 883\n",
        "mean_thick/= 883\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MaRdo6VCH9e2",
        "outputId": "d19ca92f-20c6-49e3-c31a-9421bb12ddb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training skipped due to User Input, using saved loads instead\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weights Loaded\n"
          ]
        }
      ],
      "source": [
        "if train ==True:\n",
        "  print('Training Model')\n",
        "  combined_loss=torch.empty(size=(0,11))\n",
        "\n",
        "  for epoch in range(args.max_epochs):\n",
        "      #print(epoch)\n",
        "\n",
        "      recon_thick_loss = 0\n",
        "      recon_area_loss  = 0\n",
        "      recon_func_loss  = 0\n",
        "      KL_loss          = 0\n",
        "      clf_loss         = 0\n",
        "      AE_clf_loss      = 0\n",
        "      cmr_loss         = 0\n",
        "      distances_metric = 0\n",
        "      n_thick_total    = 0\n",
        "      n_area_total     = 0\n",
        "      n_func_total     = 0\n",
        "      total_loss       = 0\n",
        "\n",
        "      for idx, (sample) in enumerate(train_dataloader):\n",
        "          func_inputs   = sample[0]\n",
        "          area_inputs   = sample[1]\n",
        "          thick_inputs  = sample[2]\n",
        "          labels        = sample[3]\n",
        "\n",
        "          out = train_autoencoders(func_inputs, area_inputs, thick_inputs,labels)\n",
        "\n",
        "          recon_thick_loss += out['thick_recon_loss']\n",
        "          recon_area_loss += out['area_recon_loss']\n",
        "          recon_func_loss += out['func_recon_loss']\n",
        "          AE_clf_loss += out['clf_loss']\n",
        "          cmr_loss    += out['cmr_loss']\n",
        "          KL_loss     += out['KL_loss']\n",
        "          distances_metric  += out['distances_metric']\n",
        "          total_loss  += out['loss']\n",
        "          out = train_classifier(func_inputs, area_inputs,thick_inputs)\n",
        "\n",
        "          clf_loss      += out['clf_loss']\n",
        "          n_thick_total += out['thick_n_samples']\n",
        "          n_area_total  += out['area_n_samples']\n",
        "          n_func_total += out['func_n_samples']\n",
        "\n",
        "\n",
        "\n",
        "      recon_thick_loss  /= n_thick_total\n",
        "      recon_area_loss   /= n_area_total\n",
        "      recon_func_loss   /= n_func_total\n",
        "      cmr_loss          /= (n_thick_total+n_area_total+n_func_total)\n",
        "      distances_metric  /= ((n_thick_total+n_area_total+n_func_total)*args.dist_factor)\n",
        "      KL_loss           /= (n_thick_total+n_area_total+n_func_total)\n",
        "      clf_loss /= (n_thick_total+n_area_total+n_func_total)\n",
        "      AE_clf_loss /= (n_thick_total+n_area_total+n_func_total)\n",
        "\n",
        "      if epoch==0:\n",
        "        combined_loss=torch.tensor([recon_thick_loss,mean_thick,recon_area_loss,mean_area,recon_func_loss,mean_func,KL_loss,AE_clf_loss,cmr_loss,AE_clf_loss,clf_loss,distances_metric,total_loss])[None,:]\n",
        "        print(combined_loss.size())\n",
        "      else:\n",
        "        combined_loss=torch.cat((combined_loss,torch.tensor([recon_thick_loss,mean_thick,recon_area_loss,mean_area,recon_func_loss,mean_func,KL_loss,AE_clf_loss,cmr_loss,AE_clf_loss,clf_loss,distances_metric,total_loss])[None,:]))\n",
        "        if epoch==1:\n",
        "          print(combined_loss.size())\n",
        "      print('Epoch: ', epoch ,'total loss: ',total_loss,  'distance metric: %.8f' % float(distances_metric), ', thick recon loss: %.8f' % float(recon_thick_loss), ', area recon loss: %.8f' % float(recon_area_loss), ', func recon loss: %.8f' % float(recon_func_loss),\n",
        "                  ', KL Div. loss: %.8f' %float (KL_loss), ', Cross-Modal loss: %.8f' % float(cmr_loss), ', AE clf loss: %.8f' % float(AE_clf_loss), ', clf loss: %.8f' % float(clf_loss))\n",
        "      print('Meanthick: ',mean_thick,'Mean area: ',mean_area,'Mean func: ',mean_func)\n",
        "  for idx in range(len(combined_loss)):\n",
        "    if idx<7:\n",
        "      plt.plot(combined_loss[:,idx])\n",
        "      #print(combined_loss[:,idx])\n",
        "\n",
        "  '''torch.save(model_thick.cpu().state_dict(),os.path.join(\"/content/drive/My Drive/BA/weights/\",  \"big_model_thick_complicated_loss_%s.pth\" % epoch))\n",
        "  torch.save  (model_area.cpu().state_dict(),os.path.join(\"/content/drive/My Drive/BA/weights/\", \"big_model_area_complicated_loss_%s.pth\" % epoch))\n",
        "  torch.save  (model_func.cpu().state_dict(), os.path.join(\"/content/drive/My Drive/BA/weights/\",\"big_model_func_complicated_loss_%s.pth\" % epoch))\n",
        "  torch.save  (netClf.cpu().state_dict(),os.path.join(\"/content/drive/My Drive/BA/weights/\",     \"big_netClf_complicated_loss_%s.pth\" % epoch))'''\n",
        "  for idx in range(len(combined_loss)):\n",
        "    if idx<12:\n",
        "      plt.plot(combined_loss[:,idx])\n",
        "      #print(combined_loss[:,idx])\n",
        "else:\n",
        "  print('Training skipped due to User Input, using saved loads instead')\n",
        "  model_thick.load_state_dict(torch.load(os.path.join      (\"/content/drive/My Drive/BA/weights/bohe_model_thick_complicated_loss_299.pth\")))\n",
        "  model_area.load_state_dict(torch.load(os.path.join       (\"/content/drive/My Drive/BA/weights/bohe_model_area_complicated_loss_299.pth\")))\n",
        "  model_func.load_state_dict(torch.load(os.path.join       (\"/content/drive/My Drive/BA/weights/bohe_model_func_complicated_loss_299.pth\")))\n",
        "  netClf.load_state_dict(torch.load(os.path.join           (\"/content/drive/My Drive/BA/weights/bohe_netClf_complicated_loss_299.pth\")))\n",
        "  print(\"Weights Loaded\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lx1hTogyNGTl"
      },
      "source": [
        "## Yang integration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQOB4Y7yBOer",
        "outputId": "bf4e921c-8639-4755-b4a8-2e83aca59da0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "def nearest_neighbour(points_a, points_b):\n",
        "      tree = spatial.KDTree(points_b)\n",
        "      return tree.query(points_a,k=50)[1]\n",
        "\n",
        "if yang == True:\n",
        "  # initialize autoencoder\n",
        "  yang_model_func    = FC_VAE  (n_input=4656,    nz=args.nz,n_hidden=args.n_hidden).to(device)\n",
        "  yang_model_thick  = FC_VAE (n_input=163842,  nz=args.nz,n_hidden=args.n_hidden).to(device)\n",
        "  yang_model_area   = FC_VAE  (n_input=163842,  nz=args.nz,n_hidden=args.n_hidden).to(device)\n",
        "  yang_netClf        = FC_Classifier(nz=args.nz).to(device)\n",
        "  yang_model_func   .load_state_dict(torch.load(os.path.join      (\"/content/drive/My Drive/BA/weights/yang_bohe_model_func_complicated_loss_308.pth\")))\n",
        "  yang_model_thick .load_state_dict(torch.load(os.path.join      (\"/content/drive/My Drive/BA/weights/yang_bohe_model_thick_complicated_loss_308.pth\")))\n",
        "  yang_model_area  .load_state_dict(torch.load(os.path.join      (\"/content/drive/My Drive/BA/weights/yang_bohe_model_area_complicated_loss_308.pth\")))\n",
        "  yang_netClf      .load_state_dict(torch.load(os.path.join      (\"/content/drive/My Drive/BA/weights/yang_bohe_netClf_complicated_loss_308.pth\")))\n",
        "  yang_model_func.to(device)\n",
        "  yang_model_thick.to(device)\n",
        "  yang_model_area.to(device)\n",
        "\n",
        "  for idx, (sample) in enumerate(test_dataloader):\n",
        "      func_inputs   = sample[0]\n",
        "      area_inputs   = sample[1]\n",
        "      thick_inputs  = sample[2]\n",
        "      labels        = sample[3]\n",
        "\n",
        "      if torch.cuda.is_available():\n",
        "          thick_inputs, area_inputs,func_inputs = thick_inputs.cuda(), area_inputs.cuda(), func_inputs.cuda()\n",
        "\n",
        "      # forward pass\n",
        "      _, thick_latents, _, _ =  yang_model_thick  (thick_inputs)\n",
        "      _, area_latents, _, _ =   yang_model_area (area_inputs)\n",
        "      _, func_latents, _, _ =   yang_model_func (func_inputs)\n",
        "\n",
        "      if idx ==0:\n",
        "        yang_thick_latent_ful,yang_area_latent_ful,yang_func_latent_ful=thick_latents,area_latents,func_latents\n",
        "\n",
        "      else:\n",
        "        yang_thick_latent_ful=torch.cat((yang_thick_latent_ful,thick_latents))\n",
        "        yang_area_latent_ful=torch.cat((yang_area_latent_ful,area_latents))\n",
        "        yang_func_latent_ful=torch.cat((yang_func_latent_ful,func_latents))\n",
        "  n=0\n",
        "  yang_neighbors = np.zeros((6,yang_func_latent_ful.size(0),50))\n",
        "  for i, lat_vec1 in enumerate([yang_area_latent_ful.detach().numpy(), yang_thick_latent_ful.detach().numpy(), yang_func_latent_ful.detach().numpy()]):\n",
        "    for j, lat_vec2 in enumerate([yang_area_latent_ful.detach().numpy(), yang_thick_latent_ful.detach().numpy(), yang_func_latent_ful.detach().numpy()]):\n",
        "      if i!=j:\n",
        "        yang_neighbors[n,:]=nearest_neighbour(lat_vec1,lat_vec2)\n",
        "        n+=1\n",
        "  yang_neighbors_acc = np.zeros((7,50))\n",
        "  for m in range(6):\n",
        "    for k in range(50):\n",
        "      acc=0\n",
        "      for i in range(yang_func_latent_ful.size(0)):\n",
        "        if i in yang_neighbors[m,i,:k]:\n",
        "          acc+=1\n",
        "      if k==0:\n",
        "        yang_neighbors_acc[m,k]=0\n",
        "      else:\n",
        "        yang_neighbors_acc[m,k]=acc/yang_func_latent_ful.size(0)\n",
        "  for k in range(50):\n",
        "    if k==0:\n",
        "      yang_neighbors_acc[6,k]=0\n",
        "    else:\n",
        "      yang_neighbors_acc[6,k]=1/(yang_func_latent_ful.size(0)/k)\n",
        "\n",
        "  yang_neighbors_acc = pd.DataFrame(yang_neighbors_acc.T, columns = ['Goal: FC, Neighbors: CSA',\n",
        "                                                'Goal: FC, Neighbors: CT',\n",
        "                                                'Goal: CSA, Neighbors: FC',\n",
        "                                                'Goal: CSA, Neighbors: CT',\n",
        "                                                'Goal: CT, Neighbors: FC',\n",
        "                                                'Goal: CT, Neighbors: CSA',\n",
        "                                                'Random Accuracy'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "mYywjpCI1QeB",
        "outputId": "7f0a412e-89c4-448c-f96d-b0cd742c368e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-14-e99a05cf6c83>\"\u001b[0;36m, line \u001b[0;32m11\u001b[0m\n\u001b[0;31m    print(criterion_classify(yang_netClf(yang_thick_latent_ful),thick_labels),\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'for' statement on line 8\n"
          ]
        }
      ],
      "source": [
        "thick_labels = torch.zeros  (yang_thick_latent_ful.shape[0]).long()\n",
        "area_labels  = torch.zeros(yang_thick_latent_ful.shape[0]).long()\n",
        "func_labels  = torch.zeros (yang_thick_latent_ful.shape[0]).long()\n",
        "\n",
        "thick_labels[:]= 0\n",
        "area_labels [:]= 1\n",
        "func_labels [:]= 2\n",
        "for i,m in enumerate((thick_latent_ful,area_latent_ful,area_latent_ful)):\n",
        "\n",
        "\n",
        "print(criterion_classify(yang_netClf(yang_thick_latent_ful),thick_labels),\n",
        "      criterion_classify(yang_netClf(yang_area_latent_ful),area_labels),\n",
        "      criterion_classify(yang_netClf(yang_func_latent_ful),func_labels))\n",
        "print(criterion_classify(netClf(thick_latent_ful),thick_labels),\n",
        "      criterion_classify(netClf(area_latent_ful),area_labels),\n",
        "      criterion_classify(netClf(func_latent_ful),func_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6QgR2Od4brQv"
      },
      "outputs": [],
      "source": [
        "'''torch.save(model_thick.cpu().state_dict(),os.path.join(\"/content/drive/My Drive/BA/weights/\",  \"bohe_model_thick_complicated_loss_%s.pth\" % epoch))\n",
        "torch.save  (model_area.cpu().state_dict(),os.path.join(\"/content/drive/My Drive/BA/weights/\", \"bohe_model_area_complicated_loss_%s.pth\" % epoch))\n",
        "torch.save  (model_func.cpu().state_dict(), os.path.join(\"/content/drive/My Drive/BA/weights/\",\"bohe_model_func_complicated_loss_%s.pth\" % epoch))\n",
        "torch.save  (netClf.cpu().state_dict(),os.path.join(\"/content/drive/My Drive/BA/weights/\",     \"bohe_netClf_complicated_loss_%s.pth\" % epoch))'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sm__Lh5IZF4J"
      },
      "source": [
        "# Clusteranalysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y0z4P84168kZ"
      },
      "outputs": [],
      "source": [
        "#import full pheno\n",
        "pheno2=pd.read_csv('/content/drive/My Drive/BA/pheno_relevant.csv', index_col=0)\n",
        "#str labels to int\n",
        "pheno2['HANDEDNESS_CATEGORY'].loc[pheno2['HANDEDNESS_CATEGORY']=='R']=0\n",
        "pheno2['HANDEDNESS_CATEGORY'].loc[pheno2['HANDEDNESS_CATEGORY']=='L']=1\n",
        "pheno2['HANDEDNESS_CATEGORY'].loc[pheno2['HANDEDNESS_CATEGORY']=='Mixed']=2\n",
        "pheno2['HANDEDNESS_CATEGORY'].loc[pheno2['HANDEDNESS_CATEGORY']=='Ambi']=2\n",
        "pheno2['HANDEDNESS_CATEGORY'].loc[pheno2['HANDEDNESS_CATEGORY']=='L->R']=2\n",
        "\n",
        "\n",
        "pheno2= pheno2.drop(['HANDEDNESS_SCORES','ADI_R_RSRCH_RELIABLE','ADOS_MODULE','SRS_AWARENESS','SRS_COGNITION','SRS_COMMUNICATION','SRS_MOTIVATION','SRS_MANNERISMS','SRS_MANNERISMS','SCQ_TOTAL','AQ_TOTAL'],axis=1)\n",
        "cluster=list(pheno2.columns)\n",
        "mytable = TableOne(pheno2,cluster, dip_test=True, normal_test=True, tukey_test=True)\n",
        "\n",
        "\n",
        "#impute missing labels for KMeans\n",
        "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "imp.fit(pheno2)\n",
        "pheno2_imputed=imp.transform(pheno2)\n",
        "\n",
        "#Get internal clustering\n",
        "# Elbow Method for K means# Import ElbowVisualizer\n",
        "\n",
        "model = KMeans()\n",
        "# k is range of number of clusters.\n",
        "visualizer_pheno = KElbowVisualizer(model, k=(2,10 ), timings= True,n_init=10)\n",
        "visualizer_pheno.fit(pheno2_imputed)        # Fit data to visualizer\n",
        "visualizer_pheno.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WtJIzY6r6-8n"
      },
      "outputs": [],
      "source": [
        "#courtesy of https://stackoverflow.com/questions/35611465/python-scikit-learn-clustering-with-missing-data\n",
        "def kmeans_missing(X, n_clusters, max_iter=10):\n",
        "    \"\"\"Perform K-Means clustering on data with missing values.\n",
        "    Args:\n",
        "      X: An [n_samples, n_features] array of data to cluster.\n",
        "      n_clusters: Number of clusters to form.\n",
        "      max_iter: Maximum number of EM iterations to perform.\n",
        "    Returns:\n",
        "      labels: An [n_samples] vector of integer labels.\n",
        "      centroids: An [n_clusters, n_features] array of cluster centroids.\n",
        "      X_hat: Copy of X with the missing values filled in.\n",
        "    \"\"\"\n",
        "\n",
        "    # Initialize missing values to their column means\n",
        "    missing = ~np.isfinite(X)\n",
        "    mu = np.nanmean(X, 0, keepdims=1)\n",
        "    X_hat = np.where(missing, mu, X)\n",
        "\n",
        "    for i in range(max_iter):\n",
        "        if i > 0:\n",
        "            # initialize KMeans with the previous set of centroids. this is much faster and makes it easier to check convergence (since labels won't be permuted on every iteration), but might be more prone togetting stuck in local minima.\n",
        "            cls = KMeans(n_clusters, init=prev_centroids)\n",
        "        else:\n",
        "            # do multiple random initializations in parallel\n",
        "            cls = KMeans(n_clusters)\n",
        "\n",
        "        # perform clustering on the filled-in data\n",
        "        labels = cls.fit_predict(X_hat)\n",
        "        centroids = cls.cluster_centers_\n",
        "\n",
        "        # fill in the missing values based on their cluster centroids\n",
        "        X_hat[missing] = centroids[labels][missing]\n",
        "\n",
        "        # when the labels have stopped changing then we have converged\n",
        "        if i > 0 and np.all(labels == prev_labels):\n",
        "            break\n",
        "\n",
        "        prev_labels = labels\n",
        "        prev_centroids = cls.cluster_centers_\n",
        "\n",
        "    return labels, centroids, X_hat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5I162UuN_mu",
        "outputId": "2c404bb6-9ce5-4a27-ae6e-c1b82df3793e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "model_thick.to(device)\n",
        "model_area.to(device)\n",
        "model_func.to(device)\n",
        "netClf.to(device)\n",
        "for idx, (sample) in enumerate(test_dataloader):\n",
        "    func_inputs   = sample[0]\n",
        "    area_inputs   = sample[1]\n",
        "    thick_inputs  = sample[2]\n",
        "    labels        = sample[3]\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        thick_inputs, area_inputs,func_inputs = thick_inputs.cuda(), area_inputs.cuda(), func_inputs.cuda()\n",
        "\n",
        "    # forward pass\n",
        "    _, thick_latents, _, _ = model_thick(thick_inputs)\n",
        "    _, area_latents, _, _ = model_area(area_inputs)\n",
        "    _, func_latents, _, _ = model_func(func_inputs)\n",
        "\n",
        "    thick_scores = netClf(thick_latents)\n",
        "    area_scores = netClf(area_latents)\n",
        "\n",
        "    func_scores = netClf(func_latents)\n",
        "    if idx ==0:\n",
        "      thick_latent_ful,area_latent_ful,func_latent_ful,labels_ful=thick_latents,area_latents,func_latents,labels\n",
        "\n",
        "    else:\n",
        "      thick_latent_ful=torch.cat((thick_latent_ful,thick_latents))\n",
        "      area_latent_ful=torch.cat((area_latent_ful,area_latents))\n",
        "      func_latent_ful=torch.cat((func_latent_ful,func_latents))\n",
        "      labels_ful=torch.cat((labels_ful,labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AMitHYA7PVe4"
      },
      "outputs": [],
      "source": [
        "def nearest_neighbour(points_a, points_b):\n",
        "    tree = spatial.KDTree(points_b)\n",
        "    return tree.query(points_a,k=50)[1]\n",
        "n=0\n",
        "neighbors = np.zeros((6,func_latent_ful.size(0),50))\n",
        "for i, lat_vec1 in enumerate([area_latent_ful.detach().numpy(), thick_latent_ful.detach().numpy(), func_latent_ful.detach().numpy()]):\n",
        "  for j, lat_vec2 in enumerate([area_latent_ful.detach().numpy(), thick_latent_ful.detach().numpy(), func_latent_ful.detach().numpy()]):\n",
        "    if i!=j:\n",
        "      neighbors[n,:]=nearest_neighbour(lat_vec1,lat_vec2)\n",
        "      n+=1\n",
        "\n",
        "neighbors_acc = np.zeros((7,50))\n",
        "\n",
        "for m in range(6):\n",
        "  for k in range(50):\n",
        "    acc=0\n",
        "    for i in range(func_latent_ful.size(0)):\n",
        "      if i in neighbors[m,i,:k]:\n",
        "        acc+=1\n",
        "    if k==0:\n",
        "      neighbors_acc[m,k]=0\n",
        "    else:\n",
        "      neighbors_acc[m,k]=acc/func_latent_ful.size(0)\n",
        "for k in range(50):\n",
        "  if k==0:\n",
        "    neighbors_acc[6,k]=0\n",
        "  else:\n",
        "    neighbors_acc[6,k]=1/(func_latent_ful.size(0)/k)\n",
        "\n",
        "neighbors_acc = pd.DataFrame(neighbors_acc.T, columns = ['Goal: FC, Neighbors: CSA',\n",
        "                                              'Goal: FC, Neighbors: CT',\n",
        "                                              'Goal: CSA, Neighbors: FC',\n",
        "                                              'Goal: CSA, Neighbors: CT',\n",
        "                                              'Goal: CT, Neighbors: FC',\n",
        "                                              'Goal: CT, Neighbors: CSA',\n",
        "                                              'Random Accuracy'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oLUYsmiEExnR"
      },
      "outputs": [],
      "source": [
        "'''np.save(\"/content/drive/My Drive/BA/bh_func_latents\",func_latent_ful.detach().cpu().numpy())\n",
        "np.save(\"/content/drive/My Drive/BA/bh_area_latents\",thick_latent_ful.detach().cpu().numpy())\n",
        "np.save(\"/content/drive/My Drive/BA/bh_thick_latents\",area_latent_ful.detach().cpu().numpy())'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jH2TbeGguqXf"
      },
      "outputs": [],
      "source": [
        "\n",
        "fig, ax = plt.subplots(1,2,figsize=(10,4), dpi=300, constrained_layout=True)\n",
        "\n",
        "ax1 = sns.lineplot(data=neighbors_acc,ax=ax[0],legend=None)\n",
        "ax1.set(ylim=(0, 1))\n",
        "box = ax1.get_position()\n",
        "ax1.set_position([box.x0, box.y0 + box.height * 0.1,\n",
        "                 box.width, box.height * 0.9])\n",
        "ax1.legend()\n",
        "\n",
        "ax1.set(xlabel=\"Number of k-nearest neighbors\", ylabel=\"k-nearest neighbors accuracy\")\n",
        "ax1.set_title(\"Our Method\")\n",
        "ax2 = sns.lineplot(data=yang_neighbors_acc,ax=ax[1])\n",
        "ax2.set(ylim=(0, 1))\n",
        "\n",
        "box = ax2.get_position()\n",
        "ax2.set_position([box.x0, box.y0 + box.height * 0.1,\n",
        "                 box.width, box.height * 0.9])\n",
        "ax2.legend(loc='upper center', bbox_to_anchor=(-0.15, -0.15),\n",
        "          fancybox=True, shadow=True, ncol=2,frameon=True)\n",
        "ax2.set_title(\"Yang et al. (2021)\")\n",
        "\n",
        "ax2.set(xlabel=\"Number of k-nearest neighbors\", ylabel=\"k-nearest neighbors accuracy\")\n",
        "\n",
        "#plt.suptitle(\"k-nearest Neighbor Accuracy of different Modality Pairs\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J3NsMI6ugsfG"
      },
      "outputs": [],
      "source": [
        "warnings.filterwarnings(\"ignore\")\n",
        "model = KMeans()\n",
        "set_palette('paired')\n",
        "fig, ax = plt.subplots(1,3,figsize=(10,3), dpi=300, constrained_layout=True)\n",
        "\n",
        "fig.suptitle(\"Distortion Score Elbow for KMeans Clusterings\")\n",
        "\n",
        "visualizer_func = KElbowVisualizer(model, k=(2,10 ), timings= False,n_init=10,ax=ax[0],vline_color=\"red\")\n",
        "visualizer_func.fit(func_latent_ful.detach().cpu().numpy())        # Fit data to visualizer\n",
        "\n",
        "ax[0].set(xlabel='k', ylabel='Distortion Score', title='Functional Connectivity', xticks=range(2,10))\n",
        "\n",
        "\n",
        "visualizer_area = KElbowVisualizer(model, k=(2,10 ), timings= False,n_init=10,ax=ax[1], metric_color='C1')\n",
        "visualizer_area.fit(area_latent_ful.detach().cpu().numpy())        # Fit data to visualizer\n",
        "ax[1].set(xlabel='k', ylabel='Distortion Score', title='Cortical Surface Area', xticks=range(2,10))\n",
        "\n",
        "visualizer_thick = KElbowVisualizer(model, k=(2,10 ), timings= False,n_init=10,ax=ax[2], metric_color='C1')\n",
        "visualizer_thick.fit(thick_latent_ful.detach().cpu().numpy())        # Fit data to visualizer\n",
        "ax[2].set(xlabel='k', ylabel='Distortion Score', title='Cortical Thickness', xticks=range(2,10))\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bLlcG88Ima_3"
      },
      "outputs": [],
      "source": [
        "kmeans_func = KMeans  (n_clusters=5, random_state=0).fit(func_latent_ful.detach().cpu().numpy())\n",
        "kmeans_area = KMeans  (n_clusters=5, random_state=0).fit(area_latent_ful.detach().cpu().numpy())\n",
        "kmeans_thick = KMeans (n_clusters=5, random_state=0).fit(thick_latent_ful.detach().cpu().numpy())\n",
        "\n",
        "\n",
        "\n",
        "print(rand_score(kmeans_area.labels_,kmeans_func.labels_))\n",
        "print(rand_score(kmeans_func.labels_,kmeans_thick.labels_))\n",
        "print(rand_score(kmeans_thick.labels_,kmeans_area.labels_))\n",
        "print(rand_score(np.random.randint(5, size=len(kmeans_func.labels_)),np.random.randint(5, size=len(kmeans_func.labels_))))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uAdgVjKEbZjS"
      },
      "outputs": [],
      "source": [
        "perm_res= permutation_test((kmeans_area.labels_,kmeans_func.labels_), rand_score,\n",
        "          n_resamples=1000, alternative='greater',permutation_type='pairings')\n",
        "print(perm_res.pvalue)\n",
        "perm_res= permutation_test((kmeans_thick.labels_,kmeans_area.labels_), rand_score,\n",
        "          n_resamples=1000, alternative='greater',permutation_type='pairings')\n",
        "print(perm_res.pvalue)\n",
        "perm_res= permutation_test((kmeans_func.labels_,kmeans_thick.labels_), rand_score,\n",
        "          n_resamples=1000, alternative='greater',permutation_type='pairings')\n",
        "print(perm_res.pvalue)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dLRrbmeoec2H"
      },
      "outputs": [],
      "source": [
        "'''for i in range(len(np.array(pheno2, dtype=float)[0,:])):\n",
        "  pheno_clustersi=kmeans_missing(np.expand_dims(np.array(pheno2, dtype=float)[:,i],axis=1),2)[0]\n",
        "  print(\"Rand_score of Latent Representation Clustering: '\",pheno2.columns[i],\"'  and Clustering based on Phenotype Data:\", rand_score(kmeans_area.labels_,pheno_clustersi[:]))\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLf5EXL_mKX2"
      },
      "source": [
        "## Get tsne representation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "62TRMcV-z4KN"
      },
      "outputs": [],
      "source": [
        "full=np.concatenate((func_latent_ful.detach().cpu().numpy(),area_latent_ful.detach().cpu().numpy(),thick_latent_ful.detach().cpu().numpy()))\n",
        "X3_embedded = TSNE(n_components=3, learning_rate='auto',init='pca', perplexity=30,random_state=0).fit_transform(np.concatenate((func_latent_ful.detach().cpu().numpy(),area_latent_ful.detach().cpu().numpy(),thick_latent_ful.detach().cpu().numpy())))\n",
        "\n",
        "X3_embedded_func = X3_embedded[:func_latent_ful.shape[0],:]\n",
        "X3_embedded_area = X3_embedded[func_latent_ful.shape[0]:(func_latent_ful.shape[0]*2),:]\n",
        "X3_embedded_thick =X3_embedded[(func_latent_ful.shape[0]*2):(func_latent_ful.shape[0]*3),:]\n",
        "\n",
        "yang_full=np.concatenate((yang_func_latent_ful.detach().cpu().numpy(),yang_area_latent_ful.detach().cpu().numpy(),yang_thick_latent_ful.detach().cpu().numpy()))\n",
        "yang_X3_embedded = TSNE(n_components=3, learning_rate='auto',init='pca', perplexity=30,random_state=0).fit_transform(yang_full)\n",
        "\n",
        "yang_X3_embedded_func = yang_X3_embedded[:func_latent_ful.shape[0],:]\n",
        "yang_X3_embedded_area = yang_X3_embedded[func_latent_ful.shape[0]:(func_latent_ful.shape[0]*2),:]\n",
        "yang_X3_embedded_thick =yang_X3_embedded[(func_latent_ful.shape[0]*2):(func_latent_ful.shape[0]*3),:]\n",
        "3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xQBSO_-wR1ee"
      },
      "outputs": [],
      "source": [
        "# tsne neighbors\n",
        "tsne_match=0\n",
        "neighbors_tsne = np.zeros((X3_embedded_func.shape[0],10))\n",
        "for i in range(X3_embedded_func.shape[0]):\n",
        "  neighbors_tsne[i]=nearest_neighbour(X3_embedded_func, X3_embedded_area)[i,0:10]\n",
        "  if i in neighbors_tsne[i]:\n",
        "    #print(i,neighbors_tsne[i])\n",
        "    tsne_match+=1\n",
        "print('accuracy of X in 10 nearest neighbors:', tsne_match/X3_embedded_func.shape[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQRIw2oamZ4r"
      },
      "source": [
        "## tSNE Visualizations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P-NkTaK_F8f9"
      },
      "outputs": [],
      "source": [
        "n=83 #participant with working matching\n",
        "\n",
        "index=list(neighbors[1,n,:10].astype(int))\n",
        "\n",
        "fig = plt.figure(figsize=(8,4), dpi= 300,constrained_layout=True)\n",
        "\n",
        "ax1 = fig.add_subplot(1, 2, 1, projection='3d')\n",
        "func_full= ax1.scatter(X3_embedded_func   [:,0], X3_embedded_func[:,1], X3_embedded_func[:,2],  marker='o',c='lightcoral'   ,alpha=0.5 ,s=10  ,label=\"Functional Connectivity\")\n",
        "area_full= ax1.scatter(X3_embedded_area   [:,0], X3_embedded_area[:,1], X3_embedded_area[:,2],   marker='^',c='cornflowerblue' ,alpha=0.5 ,s=10  ,label=\"Cortical Thickness\")\n",
        "thick_full=  ax1.scatter(X3_embedded_thick[:,0],X3_embedded_thick[:,1],X3_embedded_thick[:,2],   marker='p',c='seagreen',alpha=0.5 ,s=10,label=\"Cortical Surface Area\")\n",
        "\n",
        "plt.axis(True)\n",
        "# Hide grid lines\n",
        "ax1.grid(True)\n",
        "ax1.set_xlim(xmin=-40, xmax=40)\n",
        "ax1.set_ylim(ymin=-40, ymax=40)\n",
        "ax1.set_zlim(zmin=-40, zmax=40)\n",
        "# Hide axes ticks\n",
        "ax1.set_xticks([0])\n",
        "ax1.set_yticks([0])\n",
        "ax1.set_zticks([0])\n",
        "ax1.set_title(\"Our method\",pad=.5)\n",
        "\n",
        "ax1.legend(\"\")\n",
        "#plt.suptitle(\"3D-tSNE Visualization of Latent Space\")\n",
        "\n",
        "ax2 = fig.add_subplot(1, 2, 2, projection='3d',computed_zorder=False)\n",
        "\n",
        "func_full=   ax2.scatter(yang_X3_embedded_func   [:,0], yang_X3_embedded_func[:,1], yang_X3_embedded_func[:,2],  marker='o',c='lightcoral'   ,alpha=0.5 ,s=10 )\n",
        "area_full=   ax2.scatter(yang_X3_embedded_area   [:,0], yang_X3_embedded_area[:,1], yang_X3_embedded_area[:,2],   marker='^',c='cornflowerblue' ,alpha=0.5 ,s=10 )\n",
        "thick_full=  ax2.scatter(yang_X3_embedded_thick[:,0],yang_X3_embedded_thick[:,1],yang_X3_embedded_thick[:,2],   marker='p',c='seagreen',alpha=0.5 ,s=10   )\n",
        "\n",
        "#plt.axis(True)\n",
        "# Hide grid lines\n",
        "ax2.grid(True)\n",
        "ax2.set_xlim(xmin=-20, xmax=20)\n",
        "ax2.set_ylim(ymin=-20, ymax=20)\n",
        "ax2.set_zlim(zmin=-20, zmax=20)\n",
        "\n",
        "# Hide axes ticks\n",
        "ax2.set_xticks([0])\n",
        "ax2.set_yticks([0])\n",
        "ax2.set_zticks([0])\n",
        "ax2.set_title(\"Yang et al. (2021)\",pad=.5)\n",
        "ax2.legend(\"\")\n",
        "\n",
        "\n",
        "fig.legend(loc='lower center', bbox_to_anchor=(+.5, -0.05),\n",
        "          fancybox=True, shadow=True, ncol=3,frameon=True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RSOxShZcyelL"
      },
      "outputs": [],
      "source": [
        "from matplotlib.pyplot import plot, savefig\n",
        "\n",
        "fig = plt.figure(figsize=(6,6), dpi= 100,constrained_layout=True)\n",
        "ax = fig.add_subplot(1, 1, 1, projection='3d')\n",
        "ax.xaxis.pane.fill = False\n",
        "ax.yaxis.pane.fill = False\n",
        "ax.zaxis.pane.fill = False\n",
        "\n",
        "# Now set color to white (or whatever is \"invisible\")\n",
        "ax.xaxis.pane.set_edgecolor('w')\n",
        "ax.yaxis.pane.set_edgecolor('w')\n",
        "ax.zaxis.pane.set_edgecolor('w')\n",
        "func_full= ax.scatter(X3_embedded_func   [:,0], X3_embedded_func[:,1], X3_embedded_func[:,2],  marker='o',c='lightcoral'   ,alpha=1 ,s=20  ,label=\"Functional Connectivity\")\n",
        "area_full= ax.scatter(X3_embedded_area   [:,0], X3_embedded_area[:,1], X3_embedded_area[:,2],   marker='^',c='cornflowerblue' ,alpha=1 ,s=20  ,label=\"Cortical Surface Area\")\n",
        "thick_full=  ax.scatter(X3_embedded_thick[:,0],X3_embedded_thick[:,1],X3_embedded_thick[:,2],   marker='1',c='seagreen',alpha=1 ,s=20,label=\"Cortical Thickness\")\n",
        "\n",
        "plt.axis(True)\n",
        "# Hide grid lines\n",
        "ax.grid(True)\n",
        "ax.set_xlim(xmin=-40, xmax=40)\n",
        "ax.set_ylim(ymin=-40, ymax=40)\n",
        "ax.set_zlim(zmin=-40, zmax=40)\n",
        "# Hide axes ticks\n",
        "ax.set_xticks([0])\n",
        "ax.set_yticks([0])\n",
        "ax.set_zticks([0])\n",
        "plt.savefig('/content/drive/My Drive/BA/demo.png', transparent=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VpXJ6Y3vxAz0"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(10,4.5), dpi= 120,constrained_layout=True)\n",
        "ax = fig.add_subplot(1, 3, 1, projection='3d')\n",
        "ax.scatter(X3_embedded_func [:,0], X3_embedded_func[:,1], X3_embedded_func[:,2],  linestyle='None',  marker='o',c=\"red\",s=20 ,label=\"Functional Connectivity\")\n",
        "\n",
        "ax.set_xticks([])\n",
        "ax.set_yticks([])\n",
        "ax.set_zticks([])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "ax=fig.add_subplot(1, 3, 2, projection='3d')\n",
        "ax.scatter(X3_embedded_area [:,0], X3_embedded_area[:,1], X3_embedded_area[:,2],   marker='^',  linestyle='None', c=\"darkblue\",s=20 )\n",
        "ax.set_xticks([])\n",
        "ax.set_yticks([])\n",
        "ax.set_zticks([])\n",
        "\n",
        "\n",
        "ax=fig.add_subplot(1, 3, 3, projection='3d')\n",
        "ax.scatter(X3_embedded_thick[:,0],X3_embedded_thick[:,1],X3_embedded_thick[:,2],   marker='1',  linestyle='None', c=\"green\",s=20)\n",
        "ax.set_xticks([])\n",
        "ax.set_yticks([])\n",
        "ax.set_zticks([])\n",
        "\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cx7bnNiEZDQZ"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(10,4.5), dpi= 300,constrained_layout=True)\n",
        "ax = fig.add_subplot(1, 3, 1, projection='3d')\n",
        "ax.scatter(X3_embedded_func [:,0], X3_embedded_func[:,1], X3_embedded_func[:,2],  linestyle='None',  marker='o',c=kmeans_func.labels_,s=50 ,cmap='viridis' ,label=\"Functional Connectivity\")\n",
        "\n",
        "ax.set_xticks([0])\n",
        "ax.set_yticks([0])\n",
        "ax.set_zticks([0])\n",
        "\n",
        "\n",
        "\n",
        "plt.title(\"Latent tSNE-Representation, FC\")\n",
        "\n",
        "ax=fig.add_subplot(1, 3, 2, projection='3d')\n",
        "ax.scatter(X3_embedded_area [:,0], X3_embedded_area[:,1], X3_embedded_area[:,2],   marker='^',  linestyle='None', c=kmeans_area.labels_,s=50 ,cmap='viridis')\n",
        "ax.set_xticks([0])\n",
        "ax.set_yticks([0])\n",
        "ax.set_zticks([0])\n",
        "plt.title(\"Latent tSNE-Representation, CT\")\n",
        "\n",
        "\n",
        "ax=fig.add_subplot(1, 3, 3, projection='3d')\n",
        "ax.scatter(X3_embedded_thick[:,0],X3_embedded_thick[:,1],X3_embedded_thick[:,2],   marker='1',  linestyle='None', c=kmeans_thick.labels_,s=50,cmap='viridis')\n",
        "ax.set_xticks([0])\n",
        "ax.set_yticks([0])\n",
        "ax.set_zticks([0])\n",
        "plt.title(\"Latent tSNE-Representation, CSA\")\n",
        "\n",
        "\n",
        "\n",
        "plt.suptitle(\"Latent Representation of Functional Connectivity (z=256) in 3 component TSNE\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "97j0B0nfuuo0"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(10,5), dpi= 300,constrained_layout=True)\n",
        "ax = fig.add_subplot(1, 1, 1, projection='3d')\n",
        "\n",
        "ax.scatter(X3_embedded_area [np.where(kmeans_area.labels_==0),0], X3_embedded_area[np.where(kmeans_area.labels_==0),1], X3_embedded_area[np.where(kmeans_area.labels_==0),2],   marker='^',  linestyle='None',    c=pheno2.iloc[:,7].iloc[np.where((kmeans_area.labels_==0))],vmin=np.min(pheno2.iloc[:,7]),vmax=np.max(pheno2.iloc[:,7]),s=50 ,cmap='coolwarm')\n",
        "ax.scatter(X3_embedded_area [np.where(kmeans_area.labels_==1),0], X3_embedded_area[np.where(kmeans_area.labels_==1),1], X3_embedded_area[np.where(kmeans_area.labels_==1),2],   marker='1',  linestyle='None',    c=pheno2.iloc[:,7].iloc[np.where((kmeans_area.labels_==1))],vmin=np.min(pheno2.iloc[:,7]),vmax=np.max(pheno2.iloc[:,7]),s=50 ,cmap='coolwarm')\n",
        "ax.scatter(X3_embedded_area [np.where(kmeans_area.labels_==2),0], X3_embedded_area[np.where(kmeans_area.labels_==2),1], X3_embedded_area[np.where(kmeans_area.labels_==2),2],   marker='2',  linestyle='None',    c=pheno2.iloc[:,7].iloc[np.where((kmeans_area.labels_==2))],vmin=np.min(pheno2.iloc[:,7]),vmax=np.max(pheno2.iloc[:,7]),s=50 ,cmap='coolwarm')\n",
        "im=ax.scatter(X3_embedded_area [np.where(kmeans_area.labels_==3),0], X3_embedded_area[np.where(kmeans_area.labels_==3),1], X3_embedded_area[np.where(kmeans_area.labels_==3),2],   marker='x',  linestyle='None', c=pheno2.iloc[:,7].iloc[np.where((kmeans_area.labels_==3))],vmin=np.min(pheno2.iloc[:,7]),vmax=np.max(pheno2.iloc[:,7]),s=50 ,cmap='coolwarm')\n",
        "ax.set_xticks([0])\n",
        "ax.set_yticks([0])\n",
        "ax.set_zticks([0])\n",
        "plt.title(\"Latent tSNE-Representation, CT\")\n",
        "fig.colorbar(im,ax=ax)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qcmfiZNrz900"
      },
      "outputs": [],
      "source": [
        "X2_embedded =  TSNE (n_components=2, learning_rate='auto',init='pca', perplexity=30,random_state=0).fit_transform(np.concatenate((func_latent_ful.detach().cpu().numpy(),area_latent_ful.detach().cpu().numpy(),thick_latent_ful.detach().cpu().numpy())))\n",
        "X2_embedded_func = X2_embedded[:func_latent_ful.shape[0],:]\n",
        "X2_embedded_area = X2_embedded[func_latent_ful.shape[0]:(func_latent_ful.shape[0]*2),:]\n",
        "X2_embedded_thick = X2_embedded[(func_latent_ful.shape[0]*2):(func_latent_ful.shape[0]*3),:]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SPrYWwcJz7b_"
      },
      "outputs": [],
      "source": [
        "ax = plt.figure().add_subplot()\n",
        "\n",
        "ax.scatter(X2_embedded_area [np.where(kmeans_area.labels_==0),0], X2_embedded_area[np.where(kmeans_area.labels_==0),1],  marker='^',  linestyle='None',    c=pheno2.iloc[:,3].iloc[np.where((kmeans_area.labels_==0))],vmin=np.min(pheno2.iloc[:,3]),vmax=np.max(pheno2.iloc[:,3]),s=50 ,cmap='coolwarm')\n",
        "ax.scatter(X2_embedded_area [np.where(kmeans_area.labels_==1),0], X2_embedded_area[np.where(kmeans_area.labels_==1),1],  marker='1',  linestyle='None',    c=pheno2.iloc[:,3].iloc[np.where((kmeans_area.labels_==1))],vmin=np.min(pheno2.iloc[:,3]),vmax=np.max(pheno2.iloc[:,3]),s=50 ,cmap='coolwarm')\n",
        "ax.scatter(X2_embedded_area [np.where(kmeans_area.labels_==2),0], X2_embedded_area[np.where(kmeans_area.labels_==2),1],  marker='2',  linestyle='None',    c=pheno2.iloc[:,3].iloc[np.where((kmeans_area.labels_==2))],vmin=np.min(pheno2.iloc[:,3]),vmax=np.max(pheno2.iloc[:,3]),s=50 ,cmap='coolwarm')\n",
        "im=ax.scatter(X2_embedded_area [np.where(kmeans_area.labels_==3),0], X2_embedded_area[np.where(kmeans_area.labels_==3),1] , marker='x',  linestyle='None', c=pheno2.iloc[:,3].iloc[np.where((kmeans_area.labels_==3))],vmin=np.min(pheno2.iloc[:,3]),vmax=np.max(pheno2.iloc[:,3]),s=50 ,cmap='coolwarm')\n",
        "ax.set_xticks([])\n",
        "ax.set_yticks([])\n",
        "\n",
        "plt.title(\"Latent Representations of Cortical Thickness, Clusters and Gender (Blue: Male)\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cw0BNHz4mf3D"
      },
      "source": [
        "## Functional Reconstruction Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bu3XTU3JwqJ_"
      },
      "outputs": [],
      "source": [
        "def recon_matrix(X):\n",
        "  X1=np.zeros((97,97))\n",
        "  X1[np.triu_indices(97,k=1)]=X\n",
        "  X1 = X1 + X1.T - np.diag(np.diag(X1))\n",
        "  np.fill_diagonal(X1,np.max(X1))\n",
        "  return X1\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots(2, 4, figsize=(10, 5),dpi=300,constrained_layout=True)\n",
        "t=14\n",
        "#fig.suptitle(\"Original, Reconstructed and Crossmodal-reconstructed Functional Connectivity\")\n",
        "for i in range(t,t+2):\n",
        "  print(i)\n",
        "  test_func=model_func.cpu().decode(func_latents.cpu())[i]\n",
        "  area_to_func=model_func.cpu().decode(area_latents.cpu())[i]\n",
        "  thick_to_func=model_func.cpu().decode(thick_latents.cpu())[i]\n",
        "\n",
        "  original=recon_matrix(func_inputs[i].cpu().detach())\n",
        "  recon=  recon_matrix(test_func.cpu().detach())\n",
        "  area_recon=  recon_matrix(area_to_func.cpu().detach())\n",
        "  thick_recon=  recon_matrix(thick_to_func.cpu().detach())\n",
        "\n",
        "  sns.heatmap   (original,cmap='viridis', vmin=-4, vmax=4,ax= ax[i-t,0], annot=False,xticklabels=False, yticklabels=False)\n",
        "  sns.heatmap      (recon,cmap='viridis', vmin=-4, vmax=4,ax= ax[i-t,1], annot=False,xticklabels=False, yticklabels=False)\n",
        "  sns.heatmap (area_recon,cmap='viridis', vmin=-4, vmax=4,ax= ax[i-t,2], annot=False,xticklabels=False, yticklabels=False)\n",
        "  sns.heatmap(thick_recon,cmap='viridis', vmin=-4, vmax=4,ax= ax[i-t,3], annot=False,xticklabels=False, yticklabels=False)\n",
        "  ax[i-t,0].title.set_text('Original '+ str(i-t+1))\n",
        "  ax[i-t,1].title.set_text('Reconstruction '+ str(i-t+1))\n",
        "  ax[i-t,2].title.set_text('Reconstruction from CT '+ str(i-t+1))\n",
        "  ax[i-t,3].title.set_text('Reconstruction from CSA '+ str(i-t+1))\n",
        "\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZC_iG5vpkEz"
      },
      "source": [
        "# Group differences and Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TviRx_sEZgHj"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(3,4, figsize=(12, 6.75),dpi=300, constrained_layout=True)\n",
        "list_names=[\"ADR-I Social\",\"ADI_I Verbal\", \"ADR_I RRB\"]\n",
        "list_v=[\"ADR Social\",\"ADI Verbal\", \"ADR RRB\"]\n",
        "list_names2=[\"Diagnosis Group\",\"Age\",\"Gender\"]\n",
        "for j in range(3):\n",
        "  interim_list=[0,2,3]\n",
        "  for i in range(4):\n",
        "    ax[j,0]=sns.distplot(pheno2.iloc[:,interim_list[j]].iloc[np.where((kmeans_func.labels_==i))], ax=ax[j,0],hist=False, rug=True)\n",
        "    ax[j,0].set_title(list_names2[j]+\" (Full Sample)\")\n",
        "    ax[j,0].set_xlabel(list_names2[j])\n",
        "for j in range(3):\n",
        "  for i in range(4):\n",
        "    ax[j,1]=sns.distplot(pheno2.iloc[:,6+j].iloc[np.where((kmeans_func.labels_==i))], ax=ax[j,1],hist=False, rug=True)\n",
        "    ax[j,1].set_title(pheno2.columns[6+j] +\" (Full Sample)\")\n",
        "for j in range(3):\n",
        "  for i in range(4):\n",
        "    ax[j,2]=sns.distplot(pheno2.iloc[:,6+j].iloc[np.where((kmeans_func.labels_==i) &(pheno2.iloc[:,0]==1))], ax=ax[j,2],hist=False, rug=True)\n",
        "    ax[j,2].set_title(pheno2.columns[6+j]+\" (ASD)\")\n",
        "for j in range(3):\n",
        "  for i in range(4):\n",
        "    ax[j,3]=sns.distplot(pheno2.iloc[:,9+j].iloc[np.where((kmeans_func.labels_==i) &(pheno2.iloc[:,0]==1))], ax=ax[j,3],hist=False, rug=True)\n",
        "    ax[j,3].set_title(list_names[j])\n",
        "    ax[j,3].set_xlabel(list_v[j])\n",
        "fig.suptitle(\"Density Plots of Clusters identified in FC Representation for Phenotypic Data\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DPOuuIKdg_8F"
      },
      "outputs": [],
      "source": [
        "pheno_cont_names = ['AGE_AT_SCAN', 'FIQ',   'VIQ', 'PIQ']\n",
        "pheno_cat_names = ['SEX', 'HANDEDNESS_CATEGORY', 'DX_GROUP']\n",
        "[(pheno_cont_names+pheno_cat_names)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vEoe_SVMhNb7"
      },
      "outputs": [],
      "source": [
        "pheno2['AGE_AT_SCAN'].iloc[np.where((labels==0))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t8ldi3Evhth4"
      },
      "outputs": [],
      "source": [
        "n_clus=5\n",
        "pheno_cont_names = ['AGE_AT_SCAN', 'FIQ',   'VIQ', 'PIQ']\n",
        "pheno_cat_names = ['SEX', 'HANDEDNESS_CATEGORY', 'DX_GROUP']\n",
        "\n",
        "def split (data,pheno,labels):\n",
        "  a=data[pheno].iloc[np.where((labels==0))]\n",
        "  b=data[pheno].iloc[np.where((labels==1))]\n",
        "  c=data[pheno].iloc[np.where((labels==2))]\n",
        "  d=data[pheno].iloc[np.where((labels==3))]\n",
        "  e=data[pheno].iloc[np.where((labels==4))]\n",
        "  return [a,b,c,d,e]\n",
        "\n",
        "p_val_adj=np.zeros((3,4))\n",
        "p_val_flat=np.zeros((3,4))\n",
        "statistic=np.zeros((3,4))\n",
        "for mod in range(3):\n",
        "  if mod ==0:\n",
        "    labels=kmeans_func.labels_\n",
        "  if mod ==1:\n",
        "    labels=kmeans_area.labels_\n",
        "  if mod ==2:\n",
        "    labels=kmeans_thick.labels_\n",
        "  for n,k in enumerate(pheno_cont_names):\n",
        "    statistic[mod,n]=stats.anderson_ksamp(split(pheno2,k,labels))[0]\n",
        "    p_val_flat[mod,n]=stats.anderson_ksamp(split(pheno2,k,labels))[2]\n",
        "p_val_adj=stats.false_discovery_control(p_val_flat.flatten())\n",
        "print(p_val_adj,statistic)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QM2MtURT3ENQ"
      },
      "outputs": [],
      "source": [
        "pheno_cat_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6jeiHUBkg-Tw"
      },
      "outputs": [],
      "source": [
        "\n",
        "p_val_adj=np.zeros((3,3))\n",
        "p_val_flat=np.zeros((3,3))\n",
        "statistic=np.zeros((3,3))\n",
        "for mod in range(3):\n",
        "  if mod ==0:\n",
        "    labels=kmeans_func.labels_\n",
        "  if mod ==1:\n",
        "    labels=kmeans_area.labels_\n",
        "  if mod ==2:\n",
        "    labels=kmeans_thick.labels_\n",
        "  for n,k in enumerate(pheno_cat_names):\n",
        "    cross=pd.crosstab(labels,[pheno2[k]])\n",
        "    #print(k,stats.chi2_contingency(cross))\n",
        "    p_val_flat[mod,n]=(stats.chi2_contingency(cross)[1])\n",
        "    statistic[mod,n]=(stats.chi2_contingency(cross)[0])\n",
        "    print(k,stats.chi2_contingency(cross))\n",
        "p_val_adj=stats.false_discovery_control(p_val_flat.flatten())\n",
        "\n",
        "print(p_val_adj,statistic)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gus5ddU_gzUB"
      },
      "outputs": [],
      "source": [
        "n_clus=5\n",
        "pheno_cont_names = ['AGE_AT_SCAN', 'FIQ',   'VIQ', 'PIQ']\n",
        "pheno_cat_names = ['SEX', 'HANDEDNESS_CATEGORY', 'DX_GROUP']\n",
        "#Func\n",
        "def recon_matrix(X):\n",
        "  X1=np.zeros((n_clus,n_clus))\n",
        "  X1[np.triu_indices(n_clus,k=1)]=X\n",
        "  X1 = X1 + X1.T - np.diag(np.diag(X1))\n",
        "  np.fill_diagonal(X1,1)\n",
        "  return X1\n",
        "\n",
        "\n",
        "p_val=np.zeros    ((3,7,n_clus,n_clus))\n",
        "test_s=np.zeros    ((3,7,n_clus,n_clus))\n",
        "p_val_adj=np.zeros((3,7,n_clus,n_clus))\n",
        "p_val_flat=np.zeros((3,7,10))\n",
        "for mod in range(3):\n",
        "  if mod ==0:\n",
        "    labels=kmeans_func.labels_\n",
        "  if mod ==1:\n",
        "    labels=kmeans_area.labels_\n",
        "  if mod ==2:\n",
        "    labels=kmeans_thick.labels_\n",
        "  for n,k in enumerate(pheno_cont_names+pheno_cat_names):\n",
        "    for i in range(n_clus):\n",
        "      for j in range(n_clus):\n",
        "\n",
        "        p_val[mod,n,i,j]=stats.ks_2samp(pheno2[k].iloc[np.where((labels==i) )],\n",
        "                                    pheno2[k].iloc[np.where((labels==j) )])[1]\n",
        "        test_s[mod,n,i,j]=stats.ks_2samp(pheno2[k].iloc[np.where((labels==i) )],\n",
        "                                    pheno2[k].iloc[np.where((labels==j) )])[0]\n",
        "\n",
        "    p_val_flat[mod,n,:]=p_val[mod,n,:][np.triu_indices(n_clus,k=1)]\n",
        "\n",
        "  test_adjusted=stats.false_discovery_control(p_val_flat[mod,:])\n",
        "\n",
        "  for k in range(7):\n",
        "    p_val_adj[mod,k,:]=recon_matrix(test_adjusted[k,:])\n",
        "\n",
        "for mod in range(3):\n",
        "  for idx,i in enumerate(p_val_adj[mod,:]):\n",
        "    check=False\n",
        "    for k in i.flatten():\n",
        "      if k<=0.05 :\n",
        "        check=True\n",
        "\n",
        "    if check==True:\n",
        "      print(mod,(pheno_cont_names+pheno_cat_names)[idx],idx)\n",
        "      #print(mod,p_val_adj[mod,idx,:],test_s[mod,idx],(pheno_cont_names+pheno_cat_names)[idx],idx)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f5Tt8ThbxY91"
      },
      "outputs": [],
      "source": [
        "n_clus=5\n",
        "pheno_cont_names = ['AGE_AT_SCAN', 'FIQ',   'VIQ', 'PIQ']\n",
        "pheno_cat_names = ['SEX', 'HANDEDNESS_CATEGORY', 'DX_GROUP']\n",
        "#Func\n",
        "def recon_matrix(X):\n",
        "  X1=np.zeros((n_clus,n_clus))\n",
        "  X1[np.triu_indices(n_clus,k=1)]=X\n",
        "  X1 = X1 + X1.T - np.diag(np.diag(X1))\n",
        "  np.fill_diagonal(X1,1)\n",
        "  return X1\n",
        "\n",
        "\n",
        "p_val=np.zeros    ((3,7,n_clus,n_clus))\n",
        "test_s=np.zeros    ((3,7,n_clus,n_clus))\n",
        "p_val_adj=np.zeros((3,7,n_clus,n_clus))\n",
        "p_val_flat=np.zeros((3,7,10))\n",
        "for mod in range(3):\n",
        "  if mod ==0:\n",
        "    labels=kmeans_func.labels_\n",
        "  if mod ==1:\n",
        "    labels=kmeans_area.labels_\n",
        "  if mod ==2:\n",
        "    labels=kmeans_thick.labels_\n",
        "  for n,k in enumerate(pheno_cont_names+pheno_cat_names):\n",
        "    for i in range(n_clus):\n",
        "      for j in range(n_clus):\n",
        "\n",
        "        p_val[mod,n,i,j]=stats.ks_2samp(pheno2[k].iloc[np.where((labels==i) )],\n",
        "                                    pheno2[k].iloc[np.where((labels==j) )])[1]\n",
        "        test_s[mod,n,i,j]=stats.ks_2samp(pheno2[k].iloc[np.where((labels==i) )],\n",
        "                                    pheno2[k].iloc[np.where((labels==j) )])[0]\n",
        "\n",
        "    p_val_flat[mod,n,:]=p_val[mod,n,:][np.triu_indices(n_clus,k=1)]\n",
        "\n",
        "  test_adjusted=stats.false_discovery_control(p_val_flat[mod,:])\n",
        "\n",
        "  for k in range(7):\n",
        "    p_val_adj[mod,k,:]=recon_matrix(test_adjusted[k,:])\n",
        "\n",
        "for mod in range(3):\n",
        "  for idx,i in enumerate(p_val_adj[mod,:]):\n",
        "    check=False\n",
        "    for k in i.flatten():\n",
        "      if k<=0.05 :\n",
        "        check=True\n",
        "\n",
        "    if check==True:\n",
        "      print(mod,(pheno_cont_names+pheno_cat_names)[idx],idx)\n",
        "      #print(mod,p_val_adj[mod,idx,:],test_s[mod,idx],(pheno_cont_names+pheno_cat_names)[idx],idx)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJQEIY7Sy8ky"
      },
      "source": [
        "## RDMs & RSA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a0Y3MC9JmafG"
      },
      "outputs": [],
      "source": [
        "def get_pheno_rdm(pheno_var, is_cat=False):\n",
        "\n",
        "  diff_mat = np.zeros((len(pheno_var), len(pheno_var)))\n",
        "  min_val = min(pheno_var.flatten())\n",
        "  max_val = max(pheno_var.flatten())\n",
        "\n",
        "\n",
        "  pheno_var = (pheno_var - min_val) / (max_val - min_val)\n",
        "  for i, pheno in enumerate(pheno_var):\n",
        "      diff_mat[i] = np.abs(pheno_var - pheno)\n",
        "      if is_cat:\n",
        "          diff_mat[i] = np.where(diff_mat[i] != 0, 1, 0)\n",
        "\n",
        "  diff_mat[np.isnan(diff_mat)] = 0\n",
        "  np.fill_diagonal(diff_mat, 0)\n",
        "  return spatial.distance.squareform(diff_mat)#spatial.distance.squareform\n",
        "\n",
        "def get_latent_rdm(lat_vec):\n",
        "    dist = spatial.distance.pdist(lat_vec, metric='euclidean')\n",
        "    #print('dist', dist.shape)\n",
        "    return dist # spatial.distance.squareform(dist)\n",
        "\n",
        "def get_corr(lat_vec, pheno_var, is_cat):\n",
        "    pheno_rdm = get_pheno_rdm(pheno_var, is_cat=is_cat)\n",
        "    lat_rdm = get_latent_rdm(lat_vec)\n",
        "    # print(pheno_rdm.shape, lat_rdm.shape)\n",
        "    tau, p_tau = kendalltau(pheno_rdm, lat_rdm)\n",
        "    return tau, p_tau\n",
        "\n",
        "def statistic(x,y):\n",
        "  stat=kendalltau(x,y)[0]\n",
        "  return stat\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C35RTe-fz1u8"
      },
      "outputs": [],
      "source": [
        "pheno_cont_names = ['AGE_AT_SCAN', 'FIQ',   'VIQ', 'PIQ']\n",
        "pheno_cat_names = ['SEX', 'HANDEDNESS_CATEGORY', 'DX_GROUP']\n",
        "\n",
        "taus, ps_tau = np.zeros((3, len(pheno_cat_names)+len(pheno_cont_names))), np.zeros((3, len(pheno_cat_names)+len(pheno_cont_names)))\n",
        "rs, ps_r = np.zeros((3, len(pheno_cat_names)+len(pheno_cont_names))), np.zeros((3, len(pheno_cat_names)+len(pheno_cont_names)))\n",
        "perm_stat=np.zeros((3, len(pheno_cat_names)+len(pheno_cont_names)))\n",
        "\n",
        "\n",
        "perm_num = 1000\n",
        "perm_stat           = np.zeros((3, len(pheno_cat_names)+len(pheno_cont_names)))\n",
        "perm_pvalue         = np.zeros((3, len(pheno_cat_names)+len(pheno_cont_names)))\n",
        "perm_dist           = np.zeros((3, len(pheno_cat_names)+len(pheno_cont_names),perm_num))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gPji5OFSUBYW"
      },
      "outputs": [],
      "source": [
        "TableOne(pheno2.iloc[np.where(pheno2.iloc[:,0]==2)].iloc[:,:8], dip_test=True, normal_test=True, tukey_test=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y7xh4eUxTU40"
      },
      "outputs": [],
      "source": [
        "for i in (pheno_cont_names+pheno_cat_names):\n",
        "  print(i)\n",
        "  print (TableOne(pheno2.iloc[np.where(pheno2.iloc[:,0]==1)][i], dip_test=False, normal_test=False, tukey_test=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SUG0Hw9sz6a_"
      },
      "outputs": [],
      "source": [
        "for i, lat_vec in enumerate([area_latent_ful.detach().numpy(), thick_latent_ful.detach().numpy(), func_latent_ful.detach().numpy()]):\n",
        "    lat_rdm = get_latent_rdm(lat_vec)\n",
        "    for j, pname in enumerate(pheno_cont_names):\n",
        "        print(pname)\n",
        "        tau, p_tau = get_corr(lat_vec, np.array(pheno2[pname]), is_cat=False)\n",
        "        taus[i, j]= tau; ps_tau[i, j]= p_tau\n",
        "\n",
        "        pheno_rdm = get_pheno_rdm(np.array(pheno2[pname]), is_cat=False)\n",
        "\n",
        "        # permutation test\n",
        "        perm_res= permutation_test((pheno_rdm,lat_rdm), statistic,\n",
        "                 n_resamples=perm_num, alternative='two-sided',permutation_type='pairings')\n",
        "        perm_stat[i,j]=perm_res.statistic\n",
        "        perm_pvalue[i,j]=perm_res.pvalue\n",
        "        perm_dist[i,j]=perm_res.null_distribution\n",
        "    for j, pname in enumerate(pheno_cat_names):\n",
        "        print(pname)\n",
        "        tau, p_tau = get_corr(lat_vec, np.array(pheno2[pname]), is_cat=True)\n",
        "        taus[i, j+len(pheno_cont_names)]= tau; ps_tau[i, j+len(pheno_cont_names)]= p_tau\n",
        "\n",
        "        pheno_rdm = get_pheno_rdm(np.array(pheno2[pname]), is_cat=True)\n",
        "        # permutation test\n",
        "        perm_res= permutation_test((pheno_rdm,lat_rdm), statistic,\n",
        "                 n_resamples=perm_num, alternative='two-sided',permutation_type='pairings')\n",
        "        perm_stat[i,j+len(pheno_cont_names)]=perm_res.statistic\n",
        "        perm_pvalue[i,j+len(pheno_cont_names)]=perm_res.pvalue\n",
        "        perm_dist[i,j+len(pheno_cont_names)]=perm_res.null_distribution\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JGAKkw5a6fbv"
      },
      "outputs": [],
      "source": [
        "perm_pvalue\n",
        "test_adjusted=stats.false_discovery_control(perm_pvalue.flatten())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WlVo8tCo66OR"
      },
      "outputs": [],
      "source": [
        "perm_pvalue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hrMM_OuX6qFW"
      },
      "outputs": [],
      "source": [
        "test_adjusted,np.round(perm_stat,3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lWMMEkFt2ESc"
      },
      "outputs": [],
      "source": [
        "def plot_dens(i,j,perm_dist,perm_stat,name):\n",
        "  colors = ['seagreen', 'cornflowerblue', 'lightcoral']\n",
        "  ax[i,j].hist(perm_dist,bins=25,density=True, color='black',alpha=.8,fill =False, linewidth=1, label='Density Histogram')\n",
        "\n",
        "  # Make the normal distribution fit the data:\n",
        "  mu, std = norm.fit (perm_dist) # mean and standard deviation\n",
        "  xmin, xmax = ax[i,j].get_xlim()\n",
        "  x = np.linspace(xmin*1.5, xmax*1.5, 100)\n",
        "  p = norm.pdf(x, mu, std)\n",
        "\n",
        "  ax[i,j].plot(x, p, 'k', linewidth=2,color='lightblue', label='Density Plot')\n",
        "  ax[i,j].vlines(perm_stat,ymin=0,ymax=400,color='red', label='Empirical Tau')\n",
        "\n",
        "  section = np.linspace(mu- std * 1.96, mu+ std * 1.96,num=len(p[np.where(np.logical_and(x>=mu- std * 1.96, x<=mu+ std * 1.96))]))\n",
        "\n",
        "  ax[i,j].fill_between(section,0,p[np.where(np.logical_and(x>=mu- std * 1.96, x<=mu+ std * 1.96))],color=colors[i], alpha=.3, label='95% CI',hatch=\"//\",edgecolor=colors[i])\n",
        "  ax[i,j].plot(section,p[np.where(np.logical_and(x>=mu- std * 1.96, x<=mu+ std * 1.96))], linewidth=2,color=colors[i], alpha=.5)\n",
        "  minx=np.min(p[np.where(np.logical_and(x>=mu- std * 1.96, x<=mu+ std * 1.96))])\n",
        "\n",
        "  ax[i,j].vlines( x=mu- std * 1.96, ymin=0, ymax=minx, color=colors[i],  alpha=.5)\n",
        "  ax[i,j].vlines( x=mu+ std * 1.96, ymin=0, ymax=minx, color=colors[i],  alpha=.5)\n",
        "  ax[i,j]. set_xlabel('Kendall`s Tau')\n",
        "  if j==0:\n",
        "    ax[i,j]. set_ylabel('Density')\n",
        "  if i==0:\n",
        "    ax[i,j].title.set_text(name)\n",
        "  #ax[i,j].legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mw-1m_lJt9e2"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(3,(len(pheno_cont_names)+len(pheno_cat_names)),figsize=(18, 5), sharey=True, constrained_layout=True) #\n",
        "\n",
        "for i, lat_vec in enumerate([area_latent_ful.detach().numpy(), thick_latent_ful.detach().numpy(), func_latent_ful.detach().numpy()]):\n",
        "    lat_rdm = get_latent_rdm(lat_vec)\n",
        "    for j, pname in enumerate(pheno_cont_names):\n",
        "      plot_dens(i,j,perm_dist[i,j],perm_stat[i,j],pname)\n",
        "    for j, pname in enumerate(pheno_cat_names):\n",
        "      plot_dens(i,j+(len(pheno_cont_names)),perm_dist[i,j],perm_stat[i,j],pname)\n",
        "plt.suptitle('Permutation Testing of Tau ')\n",
        "handles, labels = ax[0,0].get_legend_handles_labels()\n",
        "leg=fig.legend(handles, labels, loc='lower center',frameon=True)\n",
        "leg.get_frame().set_edgecolor('b')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FAPhm7cAsEXs"
      },
      "outputs": [],
      "source": [
        "boot_num = 50\n",
        "boot_ci             = np.zeros((3, len(pheno_cat_names)+len(pheno_cont_names),2))\n",
        "boot_stand_err      = np.zeros((3, len(pheno_cat_names)+len(pheno_cont_names)))\n",
        "boot_dist           = np.zeros((3, len(pheno_cat_names)+len(pheno_cont_names),boot_num))\n",
        "for i, lat_vec in enumerate([area_latent_ful.detach().numpy(), thick_latent_ful.detach().numpy(), func_latent_ful.detach().numpy()]):\n",
        "    lat_rdm = get_latent_rdm(lat_vec)\n",
        "    for j, pname in enumerate(pheno_cont_names):\n",
        "        print(pname)\n",
        "        pheno_rdm = get_pheno_rdm(np.array(pheno2[pname]), is_cat=False)\n",
        "\n",
        "                # bootstrap\n",
        "        boot_res=bootstrap((pheno_rdm,lat_rdm), statistic, n_resamples=boot_num,paired=True ,vectorized=False,batch=10,method='basic')\n",
        "        boot_ci[i,j] =boot_res.confidence_interval\n",
        "        boot_stand_err[i,j]= boot_res.standard_error\n",
        "        boot_dist[i,j] = boot_res.bootstrap_distribution\n",
        "\n",
        "    for j, pname in enumerate(pheno_cat_names):\n",
        "        pheno_rdm = get_pheno_rdm(np.array(pheno2[pname]), is_cat=True)\n",
        "               # bootstrap\n",
        "        boot_res=bootstrap((pheno_rdm,lat_rdm), statistic, n_resamples=boot_num,paired=True,vectorized=False,batch=10,method='basic')\n",
        "        boot_ci[i,j+len(pheno_cont_names)] =boot_res.confidence_interval\n",
        "        boot_stand_err[i,j+len(pheno_cont_names)]= boot_res.standard_error\n",
        "        boot_dist[i,j+len(pheno_cont_names)] = boot_res.bootstrap_distribution\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qy0eLPCx03xd"
      },
      "outputs": [],
      "source": [
        "def plot_dens(i,boot_dist,boot_stand_err,name):\n",
        "  colors = ['seagreen', 'cornflowerblue', 'lightcoral']\n",
        "  bar=ax[i].bar(name,np.mean(boot_dist,axis=1),yerr=boot_stand_err*1.96,label='Barplot',color=colors[i])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gSdvhjlz6xr3"
      },
      "outputs": [],
      "source": [
        "boot_dist_m=np.mean(boot_dist.reshape(21,50),axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ahGYz286GT9"
      },
      "outputs": [],
      "source": [
        "print(boot_dist_m.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k6g1BfCo5G_o"
      },
      "outputs": [],
      "source": [
        "print(boot_dist.reshape(21,50)[7:14,:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hhfZAfe_JY3q"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "\n",
        "def bar_plot(ax, data,boot_stand_err, colors=['seagreen', 'cornflowerblue', 'lightcoral'], total_width=0.8, single_width=1, legend=True):\n",
        "    \"\"\"Draws a bar plot with multiple bars per data point.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    ax : matplotlib.pyplot.axis\n",
        "        The axis we want to draw our plot on.\n",
        "\n",
        "    data: dictionary\n",
        "        A dictionary containing the data we want to plot. Keys are the names of the\n",
        "        data, the items is a list of the values.\n",
        "\n",
        "        Example:\n",
        "        data = {\n",
        "            \"x\":[1,2,3],\n",
        "            \"y\":[1,2,3],\n",
        "            \"z\":[1,2,3],\n",
        "        }\n",
        "\n",
        "    colors : array-like, optional\n",
        "        A list of colors which are used for the bars. If None, the colors\n",
        "        will be the standard matplotlib color cyle. (default: None)\n",
        "\n",
        "    total_width : float, optional, default: 0.8\n",
        "        The width of a bar group. 0.8 means that 80% of the x-axis is covered\n",
        "        by bars and 20% will be spaces between the bars.\n",
        "\n",
        "    single_width: float, optional, default: 1\n",
        "        The relative width of a single bar within a group. 1 means the bars\n",
        "        will touch eachother within a group, values less than 1 will make\n",
        "        these bars thinner.\n",
        "\n",
        "    legend: bool, optional, default: True\n",
        "        If this is set to true, a legend will be added to the axis.\n",
        "    \"\"\"\n",
        "\n",
        "    # Check if colors where provided, otherwhise use the default color cycle\n",
        "    if colors is None:\n",
        "        colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
        "\n",
        "    # Number of bars per group\n",
        "    n_bars = len(data)\n",
        "\n",
        "    # The width of a single bar\n",
        "    bar_width = total_width / n_bars\n",
        "\n",
        "    # List containing handles for the drawn bars, used for the legend\n",
        "    bars = []\n",
        "\n",
        "    # Iterate over all data\n",
        "    for i, (name, values) in enumerate(data.items()):\n",
        "        # The offset in x direction of that bar\n",
        "        x_offset = (i - n_bars / 2) * bar_width + bar_width / 2\n",
        "\n",
        "        # Draw a bar for every value of that type\n",
        "        for x, y in enumerate(values):\n",
        "            bar = ax.bar(x + x_offset, y, width=bar_width * single_width, color=colors[i % len(colors)],yerr=boot_stand_err[i,x]*1.96,error_kw=dict(ecolor='gray', lw=1, capsize=3, capthick=.8))\n",
        "        # Add a handle to the last drawn bar, which we'll need for the legend\n",
        "        bars.append(bar[0])\n",
        "\n",
        "    # Draw legend if we need\n",
        "    if legend:\n",
        "        ax.legend(bars, data.keys(),loc='lower center', bbox_to_anchor=(+.5, -0.17),\n",
        "              fancybox=True, shadow=True, ncol=3,frameon=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6kJHkr9JJqQh"
      },
      "outputs": [],
      "source": [
        "data= {\n",
        "    \"Cortical Surface Area\"   : np.mean(boot_dist,axis=2)[0],\n",
        "    \"Cortical Thickness\"      : np.mean(boot_dist,axis=2)[1],\n",
        "    \"Functional Connectivity\" : np.mean(boot_dist,axis=2)[2]\n",
        "}\n",
        "fig, ax = plt.subplots()\n",
        "bar_plot(ax,data,boot_stand_err)\n",
        "plt.xticks(range(7), [\"Age\", \"FIQ\", \"VIQ\", \"PIQ\", \"Sex\",\"Handedness\",\"DX Group\"])\n",
        "plt.ylabel(\"Kendall's Rank Correlation Coefficient\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KWP0uktadFSw"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(3,figsize=(9, 11), sharey=True, constrained_layout=True)\n",
        "for i, lat_vec in enumerate([area_latent_ful.detach().numpy(), thick_latent_ful.detach().numpy(), func_latent_ful.detach().numpy()]):\n",
        "      lat_rdm = plot_dens(i,boot_dist[i],boot_stand_err[i],pheno_cont_names+pheno_cat_names)\n",
        "plt.suptitle('Permutation Testing of Tau ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "coSYHPn2gWB1"
      },
      "outputs": [],
      "source": [
        "boot_num = 1000\n",
        "boot_ci             = np.zeros((6, len(pheno_cat_names)+len(pheno_cont_names),2))\n",
        "boot_stand_err      = np.zeros((6, len(pheno_cat_names)+len(pheno_cont_names)))\n",
        "boot_dist           = np.zeros((6, len(pheno_cat_names)+len(pheno_cont_names),boot_num))\n",
        "for i, lat_vec in enumerate([area_latent_ful.detach().numpy(), thick_latent_ful.detach().numpy(), func_latent_ful.detach().numpy()]):\n",
        "    lat_rdm_asd = get_latent_rdm(lat_vec[np.where(pheno2.iloc[:,0]==1)])\n",
        "    lat_rdm_tc =  get_latent_rdm(lat_vec[np.where(pheno2.iloc[:,0]==1)])\n",
        "    for j, pname in enumerate(pheno_cont_names):\n",
        "        print(pname)\n",
        "        pheno_rdm_asd = get_pheno_rdm(np.array(pheno2[pname])[np.where(pheno2.iloc[:,0]==1)], is_cat=False)\n",
        "        pheno_rdm_tc =  get_pheno_rdm(np.array(pheno2[pname])[np.where(pheno2.iloc[:,0]==1)], is_cat=False)\n",
        "\n",
        "                # bootstrap\n",
        "        boot_res_asd=bootstrap((pheno_rdm_asd,lat_rdm_asd), statistic, n_resamples=boot_num,paired=True ,vectorized=False,batch=10,method='basic')\n",
        "        boot_res_tc=bootstrap((pheno_rdm_tc,lat_rdm_tc), statistic, n_resamples=boot_num,paired=True ,vectorized=False,batch=10,method='basic')\n",
        "        boot_ci[i*2,j] =boot_res_asd.confidence_interval\n",
        "        boot_stand_err[i*2,j]= boot_res_asd.standard_error\n",
        "        boot_dist[i*2,j] = boot_res_asd.bootstrap_distribution\n",
        "\n",
        "        boot_ci[i*2+1,j] =boot_res_tc.confidence_interval\n",
        "        boot_stand_err[i*2+1,j]= boot_res_tc.standard_error\n",
        "        boot_dist[i*2+1,j] = boot_res_tc.bootstrap_distribution\n",
        "\n",
        "    for j, pname in enumerate(pheno_cat_names):\n",
        "        print(pname)\n",
        "        pheno_rdm_asd = get_pheno_rdm(np.array(pheno2[pname])[np.where(pheno2.iloc[:,0]==1)], is_cat=True)\n",
        "        pheno_rdm_tc =  get_pheno_rdm(np.array(pheno2[pname])[np.where(pheno2.iloc[:,0]==1)], is_cat=True)\n",
        "        # bootstrap\n",
        "        boot_res_asd=bootstrap((pheno_rdm_asd,lat_rdm_asd), statistic, n_resamples=boot_num,paired=True ,vectorized=False,batch=10,method='basic')\n",
        "        boot_res_tc=bootstrap((pheno_rdm_tc,lat_rdm_tc), statistic, n_resamples=boot_num,paired=True ,vectorized=False,batch=10,method='basic')\n",
        "\n",
        "        boot_ci[i*2,j+len(pheno_cont_names)] =boot_res_asd.confidence_interval\n",
        "        boot_stand_err[i*2,j+len(pheno_cont_names)]= boot_res_asd.standard_error\n",
        "        boot_dist[i*2,j+len(pheno_cont_names)] = boot_res_asd.bootstrap_distribution\n",
        "\n",
        "        boot_ci[i*2+1,j+len(pheno_cont_names)] =boot_res_tc.confidence_interval\n",
        "        boot_stand_err[i*2+1,j+len(pheno_cont_names)]= boot_res_tc.standard_error\n",
        "        boot_dist[i*2+1,j+len(pheno_cont_names)] = boot_res_tc.bootstrap_distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f9ICQy0u8imU"
      },
      "outputs": [],
      "source": [
        "def plot_dens(i,boot_dist_asd,boot_stand_err_asd,boot_dist_tc,boot_stand_err_tc,name):\n",
        "\n",
        "  boot_dist = pd.DataFrame({'ASD': np.mean(boot_dist_asd,axis=1),\n",
        "                    'Typical Control': np.mean(boot_dist_tc,axis=1)}, index=name)\n",
        "  boot_stand_err = pd.DataFrame({'ASD': boot_stand_err_asd,\n",
        "                    'Typical Control': boot_stand_err_tc}, index=name)\n",
        "  print(boot_dist.shape,boot_stand_err.shape)\n",
        "  colors = ['seagreen', 'green','cornflowerblue','blue', 'lightcoral','orange']\n",
        "  ax = boot_dist.plot.bar(rot=0,yerr=boot_stand_err*1.96)\n",
        "  #bar=ax[i].bar(name,boot_dist,yerr=boot_stand_err*1.96,label='Barplot')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RD7CK80l9rGG"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(3,figsize=(9, 11), sharey=True, constrained_layout=True)\n",
        "for i, lat_vec in enumerate([area_latent_ful.detach().numpy(), thick_latent_ful.detach().numpy(), func_latent_ful.detach().numpy()]):\n",
        "      lat_rdm = plot_dens(i,boot_dist[i*2],boot_stand_err[i*2],boot_dist[i*2+1],boot_stand_err[i*2+1],pheno_cont_names+pheno_cat_names)\n",
        "plt.suptitle('Permutation Testing of Tau ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_0mGuNB6KTVS"
      },
      "outputs": [],
      "source": [
        "## Plotting\n",
        "\n",
        "print_labels = ['Age', 'FIQ', 'Sex', 'Hand', 'ASD' ,'VIQ', 'PIQ']\n",
        "titles = ['SA', 'CT', 'FC']\n",
        "colors = ['seagreen', 'cornflowerblue', 'lightcoral']\n",
        "fig, ax = plt.subplots(figsize=(18, 5), ncols=3, sharey=True)\n",
        "for i in range(3):\n",
        "    ax[i].bar(np.arange(len(taus[i])), taus[i], color=[colors[i]]*len(taus[i]))\n",
        "    ax[i].set_xticks(np.arange(len(print_labels)), print_labels);\n",
        "\n",
        "    y_position = taus[i].max() * 1.2\n",
        "    for idx, pval in enumerate(perm_stat[i,:,0]):\n",
        "      if pval>=0.95:\n",
        "          ax[i].text(x=idx, y=y_position, s=\"*\")\n",
        "ax[0].set_ylabel('Tau')\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nh94N3munrbJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nivwwGuk-CEn"
      },
      "source": [
        "## Test for subgroups"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ujcd5V_8KOBz"
      },
      "outputs": [],
      "source": [
        "# Plot for Area\n",
        "\n",
        "# Note: Choose Modality with setting data, choose phenotypic data with setting phenodata. Get all phenotypic datapoints using pheno2.columns\n",
        "data=X2_embedded_area\n",
        "phenodata=pheno2.iloc[:,3] #3 is Sex, set number to change which data to project to cmap\n",
        "ax = plt.figure().add_subplot()\n",
        "\n",
        "\n",
        "ax.scatter(data [np.where((kmeans_area.labels_==0) &(pheno2.iloc[:,0]==2)),0], data[np.where((kmeans_area.labels_==0)&(pheno2.iloc[:,0]==2)),1],  marker='^',  linestyle='None',    c=phenodata.iloc[np.where((kmeans_area.labels_==0)&(pheno2.iloc[:,0]==2))],vmin=np.min(phenodata),vmax=np.max(phenodata),s=50 ,cmap='coolwarm')\n",
        "ax.scatter(data [np.where((kmeans_area.labels_==1) &(pheno2.iloc[:,0]==2)),0], data[np.where((kmeans_area.labels_==1) &(pheno2.iloc[:,0]==2)),1],  marker='1',  linestyle='None',    c=phenodata.iloc[np.where((kmeans_area.labels_==1) &(pheno2.iloc[:,0]==2))],vmin=np.min(phenodata),vmax=np.max(phenodata),s=50 ,cmap='coolwarm')\n",
        "ax.scatter(data [np.where((kmeans_area.labels_==2) &(pheno2.iloc[:,0]==2)),0], data[np.where((kmeans_area.labels_==2) &(pheno2.iloc[:,0]==2)),1],  marker='2',  linestyle='None',    c=phenodata.iloc[np.where((kmeans_area.labels_==2) &(pheno2.iloc[:,0]==2))],vmin=np.min(phenodata),vmax=np.max(phenodata),s=50 ,cmap='coolwarm')\n",
        "im=ax.scatter(data [np.where((kmeans_area.labels_==3) &(pheno2.iloc[:,0]==2)),0], data[np.where((kmeans_area.labels_==3) &(pheno2.iloc[:,0]==2)),1] , marker='x',  linestyle='None', c=phenodata.iloc[np.where((kmeans_area.labels_==3) &(pheno2.iloc[:,0]==2))],vmin=np.min(phenodata),vmax=np.max(phenodata),s=50 ,cmap='coolwarm')\n",
        "ax.set_xticks([])\n",
        "ax.set_yticks([])\n",
        "\n",
        "plt.title(\"Latent Representations of Cortical Thickness, Clusters and \"+ pheno2.iloc[:,3].name)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DXcjG9bSLdZm"
      },
      "outputs": [],
      "source": [
        "# Plot for Area\n",
        "\n",
        "# Note: Choose Modality with setting data, choose phenotypic data with setting phenodata. Get all phenotypic datapoints using pheno2.columns\n",
        "\n",
        "data=X2_embedded_area\n",
        "phenodata=pheno2.iloc[:,3] #3 is Sex, set number to change which data to project to cmap\n",
        "ax = plt.figure().add_subplot()\n",
        "\n",
        "\n",
        "ax.scatter(data [np.where((kmeans_area.labels_==0) &(pheno2.iloc[:,0]==1)),0], data[np.where((kmeans_area.labels_==0)&(pheno2.iloc[:,0]==1)),1],  marker='^',  linestyle='None',     c=phenodata.iloc[np.where((kmeans_area.labels_==0)&(pheno2.iloc[:,0]==1))],vmin=np.min(phenodata),vmax=np.max(phenodata),s=50 ,cmap='coolwarm')\n",
        "ax.scatter(data [np.where((kmeans_area.labels_==1) &(pheno2.iloc[:,0]==1)),0], data[np.where((kmeans_area.labels_==1) &(pheno2.iloc[:,0]==1)),1],  marker='1',  linestyle='None',    c=phenodata.iloc[np.where((kmeans_area.labels_==1) &(pheno2.iloc[:,0]==1))],vmin=np.min(phenodata),vmax=np.max(phenodata),s=50 ,cmap='coolwarm')\n",
        "ax.scatter(data [np.where((kmeans_area.labels_==2) &(pheno2.iloc[:,0]==1)),0], data[np.where((kmeans_area.labels_==2) &(pheno2.iloc[:,0]==1)),1],  marker='2',  linestyle='None',    c=phenodata.iloc[np.where((kmeans_area.labels_==2) &(pheno2.iloc[:,0]==1))],vmin=np.min(phenodata),vmax=np.max(phenodata),s=50 ,cmap='coolwarm')\n",
        "im=ax.scatter(data [np.where((kmeans_area.labels_==3) &(pheno2.iloc[:,0]==1)),0], data[np.where((kmeans_area.labels_==3) &(pheno2.iloc[:,0]==1)),1] , marker='x',  linestyle='None', c=phenodata.iloc[np.where((kmeans_area.labels_==3) &(pheno2.iloc[:,0]==1))],vmin=np.min(phenodata),vmax=np.max(phenodata),s=50 ,cmap='coolwarm')\n",
        "ax.set_xticks([])\n",
        "ax.set_yticks([])\n",
        "\n",
        "plt.title(\"Latent Representations of Cortical Thickness, Clusters and \"+ pheno2.iloc[:,3].name)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAIh1Gpm9-t0"
      },
      "source": [
        "#Plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HWqO-D-RNJ_-"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(3,5, figsize=(12,7),dpi=300, constrained_layout=True)\n",
        "list_index=[3,2,6,7,8]\n",
        "mod_index=[2,0,1]\n",
        "for idx,i in enumerate(list_index):\n",
        "  for idy,mod in enumerate(mod_index):\n",
        "    print(mod)\n",
        "    check=False\n",
        "    for k in p_val_adj[mod,i].flatten():\n",
        "      if k<=0.05 :\n",
        "        check=True\n",
        "    if check==True:\n",
        "      sns.heatmap(np.round(p_val_adj[mod,i,:],3),cbar=False,annot=True,vmin=0,ax=ax[idy,idx],annot_kws={\"size\":8})\n",
        "\n",
        "rows = [ 'CSA','FC', 'CT']\n",
        "cols =[\"Sex\",\"Age\",\"Full-Scale IQ\", \"Verbal IQ\", \"Performance IQ\"]\n",
        "\n",
        "ax[0,0].set_title(cols[0])\n",
        "ax[0,1].set_title(cols[1])\n",
        "ax[0,2].set_title(cols[2])\n",
        "ax[0,3].set_title(cols[3])\n",
        "ax[0,4].set_title(cols[4])\n",
        "\n",
        "for ax, row in zip(ax[:,0], rows):\n",
        "    ax.set_ylabel(row, rotation=45,)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZ3MIGpDm3Rr"
      },
      "source": [
        "## Reconstruction Performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C4sBahxax-wJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e55e9901-9110-49dd-d6a5-94e4236e2c60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "isfunc=np.load(\"/content/drive/My Drive/BA/isfunc.npy\", allow_pickle=True)\n",
        "#Pheno Data\n",
        "pheno_data=pd.read_csv('/content/drive/My Drive/BA/pheno_data.csv', index_col=0)\n",
        "pheno_data.iloc[isfunc==1]\n",
        "\n",
        "#Functional Data\n",
        "func_data= np.load(\"/content/drive/My Drive/BA/func_flat_Tal_new.npy\", allow_pickle=True)\n",
        "func_data[np.where(np.isnan(func_data))]=0\n",
        "func_data= (func_data - np.mean(func_data)) / np.std(func_data)\n",
        "func_data_recon=model_func.decode(func_latent_ful).detach().numpy()\n",
        "thick_to_func=model_func.decode(thick_latent_ful.cpu()).detach().numpy()\n",
        "area_to_func =model_func.decode( area_latent_ful.cpu()).detach().numpy()\n",
        "\n",
        "#Area Data\n",
        "area_data=np.load('/content/drive/My Drive/BA/area_data_red.npy')[:,:,0].T\n",
        "area_data=(area_data - np.mean(area_data)) / np.std(area_data)\n",
        "area_data=area_data[isfunc==1]\n",
        "\n",
        "area_data_recon=(model_area.decode(area_latent_ful).detach().numpy())\n",
        "func_to_area= model_area.cpu().decode(func_latent_ful .cpu()).detach().numpy()\n",
        "thick_to_area=model_area.cpu().decode(thick_latent_ful.cpu()).detach().numpy()\n",
        "\n",
        "#Cortical Thickness Data\n",
        "thick_data=np.load('/content/drive/My Drive/BA/thick_data_red.npy')[:,:,0].T\n",
        "thick_data=(thick_data - np.mean(thick_data)) / np.std(thick_data)\n",
        "thick_data=thick_data[isfunc==1]\n",
        "\n",
        "thick_data_recon=model_thick.decode(thick_latent_ful).detach().numpy()\n",
        "func_to_thick=model_thick.cpu().decode(func_latent_ful.cpu()).detach().numpy()\n",
        "area_to_thick=model_thick.cpu().decode(area_latent_ful.cpu()).detach().numpy()\n",
        "\n",
        "\n",
        "## Yang\n",
        "yang_func_data_recon=yang_model_func.decode(yang_func_latent_ful).detach().numpy()\n",
        "yang_thick_to_func=  yang_model_func.decode(yang_thick_latent_ful.cpu()).detach().numpy()\n",
        "yang_area_to_func =  yang_model_func.decode( yang_area_latent_ful.cpu()).detach().numpy()\n",
        "\n",
        "yang_area_data_recon=(yang_model_area.decode(yang_area_latent_ful).detach().numpy())\n",
        "yang_func_to_area=    yang_model_area.cpu().decode(yang_func_latent_ful .cpu()).detach().numpy()\n",
        "yang_thick_to_area=   yang_model_area.cpu().decode(yang_thick_latent_ful.cpu()).detach().numpy()\n",
        "\n",
        "yang_thick_data_recon=yang_model_thick.decode(yang_thick_latent_ful).detach().numpy()\n",
        "yang_func_to_thick=   yang_model_thick.cpu().decode(yang_func_latent_ful.cpu()).detach().numpy()\n",
        "yang_area_to_thick=   yang_model_thick.cpu().decode(yang_area_latent_ful.cpu()).detach().numpy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BUyaibLtQkst"
      },
      "outputs": [],
      "source": [
        "func_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WCzWppNfJRxH"
      },
      "outputs": [],
      "source": [
        "def MSE(a,b):\n",
        "  print(np.square(np.subtract(a,b)).shape)\n",
        "  mse=np.square(np.subtract(a,b)).mean()\n",
        "  return mse\n",
        "def losses(original, reconstruction,b2a,c2a):\n",
        "  recon_loss=MSE(original,reconstruction)\n",
        "  cmr_a=MSE(original,b2a)\n",
        "  cmr_b=MSE(original,c2a)\n",
        "  recon_loss_mod=MSE(original,np.mean(original,axis=0))\n",
        "  return [recon_loss,cmr_a,cmr_b,recon_loss_mod]\n",
        "\n",
        "for i,(name,orig,recon,b2a,c2a) in enumerate([['Func',func_data,func_data_recon,thick_to_func,area_to_func],['Thick',thick_data,func_to_thick,thick_data_recon,area_to_thick],['Area',area_data,func_to_area,thick_to_area,area_data_recon]]):\n",
        "  if i==0:\n",
        "    loss_ful=pd.DataFrame(losses(orig,recon,b2a,c2a),index=[\"Reconstruction\",\"Modality improvement\", \"cmr_a\",\"cmr_b\"])\n",
        "  else:\n",
        "    loss_ful=pd.concat([loss_ful,pd.DataFrame(losses(orig,recon,b2a,c2a),index=[\"Reconstruction\",\"Modality improvement\", \"cmr_a\",\"cmr_b\"])],axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AYH4-XOfREiB"
      },
      "outputs": [],
      "source": [
        "loss_ful.T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vq2KCGent5TE"
      },
      "outputs": [],
      "source": [
        "\n",
        "for i,(name,orig,recon,b2a,c2a) in enumerate([['Func',func_data,yang_func_data_recon,yang_thick_to_func,yang_area_to_func],['Thick',thick_data,yang_func_to_thick,yang_thick_data_recon,yang_area_to_thick],['Area',area_data,yang_func_to_area,yang_thick_to_area,yang_area_data_recon]]):\n",
        "  if i==0:\n",
        "    loss_ful=pd.DataFrame(losses(orig,recon,b2a,c2a),index=[\"Reconstruction\",\"Modality improvement\", \"cmr_a\",\"cmr_b\"])\n",
        "  else:\n",
        "    loss_ful=pd.concat([loss_ful,pd.DataFrame(losses(orig,recon,b2a,c2a),index=[\"Reconstruction\",\"Modality improvement\", \"cmr_a\",\"cmr_b\"])],axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p3DVAFWcUYh5"
      },
      "outputs": [],
      "source": [
        "loss_ful.T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yS-qvKkvUFcl"
      },
      "outputs": [],
      "source": [
        "def upscale (input):\n",
        "  print(input.shape)\n",
        "  upscaled=np.zeros((input.shape[0]*2))\n",
        "  print(upscaled.shape)\n",
        "  upscaled[np.arange(0,upscaled.shape[0],2)]=input\n",
        "  upscaled[np.arange(1,upscaled.shape[0],2)]=input\n",
        "  return(upscaled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NlSGuPnvdjuJ"
      },
      "outputs": [],
      "source": [
        "input=func_data\n",
        "reconby=func_latent_ful\n",
        "reconby1=area_latent_ful\n",
        "reconby2=thick_latent_ful\n",
        "print(np.round(np.sum(np.abs(model_func.decode(reconby).detach().numpy()-input))/(input.shape[0]*input.shape[1]),3))\n",
        "print(np.round(np.std(np.abs(model_func.decode(reconby).detach().numpy()-input)),3))\n",
        "print(np.round(np.sum(np.abs(model_func.decode(reconby1).detach().numpy()-input))/(input.shape[0]*input.shape[1]),3))\n",
        "print(np.round(np.std(np.abs(model_func.decode(reconby1).detach().numpy()-input)),3))\n",
        "print(np.round(np.sum(np.abs(model_func.decode(reconby2).detach().numpy()-input))/(input.shape[0]*input.shape[1]),3))\n",
        "print(np.round(np.std(np.abs(model_func.decode(reconby2).detach().numpy()-input)),3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2gyaadZYl8gg"
      },
      "outputs": [],
      "source": [
        "input=func_data\n",
        "reconby=func_latent_ful\n",
        "reconby1=area_latent_ful\n",
        "reconby2=thick_latent_ful\n",
        "print(np.round((np.abs(model_func.decode(reconby).detach().numpy()-input)),3))\n",
        "print(np.round((np.abs(model_func.decode(reconby1).detach().numpy()-input))/(input.shape[0]*input.shape[1]),3))\n",
        "print(np.round((np.abs(model_func.decode(reconby1).detach().numpy()-input)),3))\n",
        "print(np.round((np.abs(model_func.decode(reconby2).detach().numpy()-input))/(input.shape[0]*input.shape[1]),3))\n",
        "print(np.round(np.std(np.abs(model_func.decode(reconby2).detach().numpy()-input)),3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zmdYPZ406g3v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8f5b3c8b-2cdb-4d79-e0fa-95fae999a149"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x1000 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "def recon_matrix(X):\n",
        "  X1=np.zeros((97,97))\n",
        "  X1[np.triu_indices(97,k=1)]=X\n",
        "  X1 = X1 + X1.T - np.diag(np.diag(X1))\n",
        "  np.fill_diagonal(X1,np.nan)\n",
        "  return X1\n",
        "fig = plt.figure(figsize=(2,2),dpi= 500,constrained_layout=True)\n",
        "sns.heatmap(recon_matrix(area_to_func[0]),cbar=True,cmap=\"coolwarm\",annot=False,square=True,xticklabels=False,yticklabels=False,vmin=-3,vmax=3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BAT0_woin0CM"
      },
      "source": [
        "## Recon fMRI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NmN9DeRSPvNt"
      },
      "outputs": [],
      "source": [
        "def recon_matrix(X):\n",
        "  X1=np.zeros((97,97))\n",
        "  X1[np.triu_indices(97,k=1)]=X\n",
        "  X1 = X1 + X1.T - np.diag(np.diag(X1))\n",
        "  np.fill_diagonal(X1,np.nan)\n",
        "  return X1\n",
        "fig = plt.figure(figsize=(12,12), dpi= 300,constrained_layout=True)\n",
        "\n",
        "\n",
        "ax = fig.add_subplot(3,3, 1)\n",
        "sns.heatmap(recon_matrix(np.mean(model_func.decode(func_latent_ful).detach().numpy()-func_data,0)),ax=ax,cmap=\"coolwarm\",annot=False,square=True,xticklabels=False,yticklabels=False)\n",
        "\n",
        "ax.set_title(\"Functional Connectivity (Full Sample)\")\n",
        "\n",
        "ax = fig.add_subplot(3,3, 2, projection='3d')\n",
        "\n",
        "plotting.plot_surf_stat_map(datasets.fetch_surf_fsaverage(mesh='fsaverage').white_left,np.mean(model_area.decode(area_latent_ful).detach().numpy()-thick_data,0),axes=ax,colorbar=True,cmap='coolwarm')\n",
        "ax.set_title(\"Cortical Thickness (Full Sample)\")\n",
        "ax = fig.add_subplot(3,3, 3, projection='3d')\n",
        "\n",
        "plotting.plot_surf_stat_map(datasets.fetch_surf_fsaverage(mesh='fsaverage').white_left,np.mean(model_thick.decode(thick_latent_ful).detach().numpy()-area_data,0),axes=ax,colorbar=True,cmap='coolwarm')\n",
        "ax.set_title(\"Cortical Surface Area (Full Sample)\")\n",
        "\n",
        "ax = fig.add_subplot(3,3, 4)\n",
        "sns.heatmap(recon_matrix(np.mean(model_func.decode(func_latent_ful[np.where(pheno2.iloc[:,0]==1)]).detach().numpy()-func_data[np.where(pheno2.iloc[:,0]==1)],0)),ax=ax,cmap=\"coolwarm\",annot=False,square=True,xticklabels=False,yticklabels=False)\n",
        "\n",
        "ax.set_title(\"Functional Connectivity (ASD)\")\n",
        "\n",
        "ax = fig.add_subplot(3,3, 5, projection='3d')\n",
        "\n",
        "plotting.plot_surf_stat_map(datasets.fetch_surf_fsaverage(mesh='fsaverage').white_left,np.mean(model_area.decode(area_latent_ful[np.where(pheno2.iloc[:,0]==1)]).detach().numpy()-thick_data[np.where(pheno2.iloc[:,0]==1)],0),axes=ax,colorbar=True,cmap='coolwarm')\n",
        "ax.set_title(\"Cortical Thickness (ASD)\")\n",
        "ax = fig.add_subplot(3,3, 6, projection='3d')\n",
        "\n",
        "plotting.plot_surf_stat_map(datasets.fetch_surf_fsaverage(mesh='fsaverage').white_left,np.mean(model_thick.decode(thick_latent_ful[np.where(pheno2.iloc[:,0]==1)]).detach().numpy()-area_data[np.where(pheno2.iloc[:,0]==1)],0),axes=ax,colorbar=True,cmap='coolwarm')\n",
        "ax.set_title(\"Cortical Surface Area (ASD)\")\n",
        "\n",
        "\n",
        "ax = fig.add_subplot(3,3, 7)\n",
        "sns.heatmap(recon_matrix(np.mean(model_func.decode(func_latent_ful[np.where(pheno2.iloc[:,0]==2)]).detach().numpy()-func_data[np.where(pheno2.iloc[:,0]==2)],0)),ax=ax,cmap=\"coolwarm\",annot=False,square=True,xticklabels=False,yticklabels=False)\n",
        "\n",
        "ax.set_title(\"Functional Connectivity (Typical Control)\")\n",
        "\n",
        "ax = fig.add_subplot(3,3, 8, projection='3d')\n",
        "\n",
        "plotting.plot_surf_stat_map(datasets.fetch_surf_fsaverage(mesh='fsaverage').white_left,np.mean(model_area.decode(area_latent_ful[np.where(pheno2.iloc[:,0]==2)]).detach().numpy()-thick_data[np.where(pheno2.iloc[:,0]==2)],0),axes=ax,colorbar=True,cmap='coolwarm')\n",
        "ax.set_title(\"Cortical Thickness (Typical Control)\")\n",
        "ax = fig.add_subplot(3,3, 9, projection='3d')\n",
        "\n",
        "plotting.plot_surf_stat_map(datasets.fetch_surf_fsaverage(mesh='fsaverage').white_left,np.mean(model_thick.decode(thick_latent_ful[np.where(pheno2.iloc[:,0]==2)]).detach().numpy()-area_data[np.where(pheno2.iloc[:,0]==2)],0),axes=ax,colorbar=True,cmap='coolwarm')\n",
        "ax.set_title(\"Cortical Surface Area (Typical Control)\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WhcMcqnmP1pS"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(constrained_layout=True)\n",
        "\n",
        "\n",
        "ax = fig.add_subplot(111,projection='3D')\n",
        "plotting.plot_surf_stat_map(datasets.fetch_surf_fsaverage(mesh='fsaverage').white_left,np.mean(model_area.decode(area_latent_ful[np.where(pheno2.iloc[:,0]==2)]).detach().numpy()-thick_data[np.where(pheno2.iloc[:,0]==2)],0),axes=ax,colorbar=True,cmap='coolwarm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UakGclammfMc"
      },
      "outputs": [],
      "source": [
        "def recon_matrix(X):\n",
        "  X1=np.zeros((97,97))\n",
        "  X1[np.triu_indices(97,k=1)]=X\n",
        "  X1 = X1 + X1.T - np.diag(np.diag(X1))\n",
        "  np.fill_diagonal(X1,np.nan)\n",
        "  return X1\n",
        "\n",
        "fig, ax = plt.subplots(2,4, figsize=(16,7),dpi=300, constrained_layout=True)\n",
        "input=func_data\n",
        "reconby=func_latent_ful\n",
        "reconby1=area_latent_ful\n",
        "reconby2=thick_latent_ful\n",
        "\n",
        "\n",
        "sns.heatmap(recon_matrix(np.mean(input-np.mean(input,0),0)),cmap=\"coolwarm\",ax=ax[0,0])\n",
        "\n",
        "sns.heatmap(recon_matrix(np.std(input-np.mean(input,0),0)),cmap=\"coolwarm\",ax=ax[1,0])\n",
        "\n",
        "sns.heatmap(recon_matrix(np.mean(model_func.decode(reconby).detach().numpy()-input,0)),cmap=\"coolwarm\",ax=ax[0,1])\n",
        "\n",
        "sns.heatmap(recon_matrix(np.std(model_func.decode(reconby).detach().numpy()-input,0)),cmap=\"coolwarm\",ax=ax[1,1],vmax=1)\n",
        "\n",
        "sns.heatmap(recon_matrix(np.mean(model_func.decode(reconby1).detach().numpy()-input,0)),cmap=\"coolwarm\",ax=ax[0,2])\n",
        "sns.heatmap(recon_matrix(np.std(model_func.decode(reconby1).detach().numpy()-input,0)),cmap=\"coolwarm\",ax=ax[1,2],vmax=1)\n",
        "\n",
        "\n",
        "sns.heatmap(recon_matrix(np.mean(model_func.decode(reconby2).detach().numpy()-input,0)),cmap=\"coolwarm\",ax=ax[0,3])\n",
        "sns.heatmap(recon_matrix(np.std(model_func.decode(reconby2).detach().numpy()-input,0)),cmap=\"coolwarm\",ax=ax[1,3],vmax=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0jT2GBMo7E6"
      },
      "source": [
        "# Brain Crossmodal Reconstruction Visualizations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RzM7Y8BTQxJX"
      },
      "outputs": [],
      "source": [
        "fsaverage=datasets.fetch_surf_fsaverage(mesh='fsaverage')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BgtBnEFOmJ02"
      },
      "outputs": [],
      "source": [
        "\n",
        "area_data=np.load('/content/drive/My Drive/BA/full_data_thick.npy')[:,:,0].T\n",
        "area_data=(area_data - np.mean(area_data)) / np.std(area_data)\n",
        "#Cortical Thickness Data\n",
        "thick_data=np.load('/content/drive/My Drive/BA/full_data_area.npy')[:,:,0].T\n",
        "thick_data=(thick_data - np.mean(thick_data)) / np.std(thick_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PQjzZafujDZ9"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(dpi= 100,constrained_layout=True)\n",
        "ax = fig.add_subplot(1, 1, 1, projection='3d')\n",
        "plot=plotting.plot_surf_stat_map(\n",
        "          fsaverage.pial_left, thick_data[0], colorbar=False,axes=ax,cmap=\"Blues\", bg_map=fsaverage['sulc_left'], bg_on_data=True,darkness=0.5)\n",
        "plot.figure.savefig('/content/drive/My Drive/BA/thickness.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bqwTKsFatk-w"
      },
      "outputs": [],
      "source": [
        "savefig('/content/drive/My Drive/BA/demo2.png', transparent=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rc0WUAt8Qj_i"
      },
      "outputs": [],
      "source": [
        "def plot_brain(data,plot_n):\n",
        "  ax = fig.add_subplot(2, 2, plot_n*4+1, projection='3d')\n",
        "  plotting.plot_surf_stat_map(\n",
        "          fsaverage.infl_left, upscale(data)[len(data):], hemi='left', colorbar=False,axes=ax,cmap=\"coolwarm\", bg_map=fsaverage['sulc_left'], bg_on_data=True,darkness=.3)\n",
        "  ax = fig.add_subplot(2, 2, plot_n*4+2, projection='3d')\n",
        "  plotting.plot_surf_stat_map(\n",
        "        fsaverage.infl_left, upscale(data)[len(data):], hemi='left', colorbar=False ,axes=ax,cmap=\"coolwarm\", bg_map=fsaverage['sulc_left'], bg_on_data=True,view='medial')\n",
        "  ax = fig.add_subplot(2, 2, plot_n*4+3, projection='3d')\n",
        "  plotting.plot_surf_stat_map(\n",
        "        fsaverage.infl_right, upscale(data)[:len(data)], hemi='right', colorbar=False, bg_map=fsaverage['sulc_right'], bg_on_data=True,cmap=\"coolwarm\",axes=ax)\n",
        "  ax = fig.add_subplot(2, 2, plot_n*4+4, projection='3d')\n",
        "  plotting.plot_surf_stat_map(\n",
        "        fsaverage.infl_right, upscale(data)[:len(data)], hemi='right', colorbar=False, bg_map=fsaverage['sulc_right'], bg_on_data=True,cmap=\"coolwarm\",axes=ax,view='medial')\n",
        "\n",
        "\n",
        "fig = plt.figure(dpi= 300)\n",
        "\n",
        "for i, data  in enumerate([area_data[0]]):\n",
        "  plot_brain(data,i)\n",
        "\n",
        "\n",
        "plt.subplots_adjust(wspace=0, hspace=0)\n",
        "cbar_ax = fig.add_axes([0.85, 0.15, 0.05, 0.7])\n",
        "fig.colorbar(ax)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "fig, axes = plt.subplots(2,2,figsize=(6,6),subplot_kw=dict(projection='3d'))\n",
        "ax = axes.ravel()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "im=plotting.plot_surf_stat_map(\n",
        "          fsaverage.infl_left, upscale(func_to_thick[0])[len(data):], hemi='left', colorbar=False,axes=ax[0],cmap=\"coolwarm\", bg_map=fsaverage['sulc_left'], bg_on_data=True,darkness=.3,vmin=-3,vmax=3)\n",
        "im=plotting.plot_surf_stat_map(\n",
        "      fsaverage.infl_left, upscale(func_to_thick[0])[len(data):], hemi='left', colorbar=False ,axes=ax[1],cmap=\"coolwarm\", bg_map=fsaverage['sulc_left'], bg_on_data=True,view='medial',vmin=-3,vmax=3)\n",
        "im=plotting.plot_surf_stat_map(\n",
        "      fsaverage.infl_right, upscale(func_to_thick[0])[:len(data)], hemi='right', colorbar=False, bg_map=fsaverage['sulc_right'], bg_on_data=True,cmap=\"coolwarm\",axes=ax[2],vmin=-3,vmax=3)\n",
        "im=plotting.plot_surf_stat_map(\n",
        "      fsaverage.infl_right, upscale(func_to_thick[0])[:len(data)], hemi='right', colorbar=False, bg_map=fsaverage['sulc_right'], bg_on_data=True,cmap=\"coolwarm\",axes=ax[3],view='medial',vmin=-3,vmax=3)\n",
        "\n",
        "\n",
        "plt.subplots_adjust(wspace=0, hspace=0)\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Dpf1Fqrwlzng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rqPRH0DlCFd6"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(3,6),dpi= 300,constrained_layout=True)\n",
        "\n",
        "for i, data  in enumerate([thick_data_mean,thick_recon]):\n",
        "  plot_brain(data,i)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c0bCpQJi_L_E"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(3,6),dpi= 300,constrained_layout=True)\n",
        "for i in range (8):\n",
        "ax = fig.add_subplot(2, 4, 1, projection='3d')\n",
        "plotting.plot_surf_stat_map(\n",
        "        fsaverage.infl_left, upscale(area_data_mean)[len(area_data_mean):], hemi='left', colorbar=False,axes=ax,cmap=\"coolwarm\", bg_map=fsaverage['sulc_left'], bg_on_data=True,darkness=.3)\n",
        "\n",
        "\n",
        "ax = fig.add_subplot(2, 4, 2, projection='3d')\n",
        "plotting.plot_surf_stat_map(\n",
        "        fsaverage.infl_left, upscale(area_data_mean)[len(area_data_mean):], hemi='left', colorbar=True ,axes=ax,cmap=\"coolwarm\", bg_map=fsaverage['sulc_left'], bg_on_data=True,view='medial')\n",
        "\n",
        "ax = fig.add_subplot(2, 4, 3, projection='3d')\n",
        "plotting.plot_surf_stat_map(\n",
        "        fsaverage.infl_right, upscale(area_data_mean)[:len(area_data_mean)], hemi='right', colorbar=False, bg_map=fsaverage['sulc_right'], bg_on_data=True,cmap=\"coolwarm\",axes=ax)\n",
        "ax = fig.add_subplot(2, 4, 4, projection='3d')\n",
        "plotting.plot_surf_stat_map(\n",
        "        fsaverage.infl_right, upscale(area_data_mean)[:len(area_data_mean)], hemi='right', colorbar=True, bg_map=fsaverage['sulc_right'], bg_on_data=True,cmap=\"coolwarm\",axes=ax,view='medial')\n",
        "\n",
        "ax = fig.add_subplot(2, 4, 5, projection='3d')\n",
        "plotting.plot_surf_stat_map(\n",
        "        fsaverage.infl_left, upscale(area_recon)[len(area_recon):], hemi='left', colorbar=False, bg_map=fsaverage['sulc_left'], bg_on_data=True,cmap=\"coolwarm\",axes=ax)\n",
        "ax = fig.add_subplot(2, 4, 6, projection='3d')\n",
        "plotting.plot_surf_stat_map(\n",
        "        fsaverage.infl_left, upscale(area_recon)[len(area_recon):], hemi='left', colorbar=True, bg_map=fsaverage['sulc_left'], bg_on_data=True,cmap=\"coolwarm\",axes=ax,view='medial')\n",
        "\n",
        "ax =fig.add_subplot(2, 4, 7, projection='3d')\n",
        "plotting.plot_surf_stat_map(\n",
        "        fsaverage.infl_right, upscale(area_recon)[:len(area_recon)], hemi='right', colorbar=False, bg_map=fsaverage['sulc_right'], bg_on_data=True,cmap=\"coolwarm\",axes=ax)\n",
        "ax = fig.add_subplot(2, 4, 8, projection='3d')\n",
        "plotting.plot_surf_stat_map(\n",
        "        fsaverage.infl_right, upscale(area_recon)[:len(area_recon)], hemi='right', colorbar=True, bg_map=fsaverage['sulc_right'], bg_on_data=True,cmap=\"coolwarm\",axes=ax,view='medial')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KWHEpf1AkL0s"
      },
      "outputs": [],
      "source": [
        "\n",
        "fig = plt.figure(figsize=(12,6), dpi= 300,constrained_layout=True)\n",
        "\n",
        "for i,data in enumerate([area_data_mean,area_recon,func_to_area,thick_to_area,thick_data_mean,thick_recon,func_to_thick,area_to_thick]):\n",
        "  ax = fig.add_subplot(2, 4, i+1, projection='3d')\n",
        "  plotting.plot_surf_stat_map(datasets.fetch_surf_fsaverage(mesh='fsaverage').white_left,upscale(data)[len(data):],axes=ax,colorbar=True,cmap='viridis')\n",
        "'''\n",
        "ax.set_title(\"Average Normalized CSA\")\n",
        "\n",
        "ax = fig.add_subplot(2, 4, 2, projection='3d')\n",
        "plotting.plot_surf_stat_map(datasets.fetch_surf_fsaverage(mesh='fsaverage').white_left,thick_recon.flatten(),axes=ax,colorbar=True,cmap='viridis')\n",
        "ax.set_title(\"Average Reconstructed CSA\")\n",
        "\n",
        "ax = fig.add_subplot(2, 4, 3, projection='3d')\n",
        "plotting.plot_surf_stat_map(datasets.fetch_surf_fsaverage(mesh='fsaverage').white_left,func_to_thick,axes=ax,colorbar=True,cmap='viridis')\n",
        "ax.set_title(\"Average FC -> CSA\")\n",
        "\n",
        "ax = fig.add_subplot(2, 4, 4, projection='3d')\n",
        "plotting.plot_surf_stat_map(datasets.fetch_surf_fsaverage(mesh='fsaverage').white_left,area_to_thick,axes=ax,colorbar=True,cmap='viridis')\n",
        "\n",
        "ax.set_title(\"Average CT -> CSA\")\n",
        "\n",
        "ax = fig.add_subplot(2, 4, 5, projection='3d')\n",
        "plotting.plot_surf_stat_map(datasets.fetch_surf_fsaverage(mesh='fsaverage').white_left,thick_data_mean,axes=ax,colorbar=True,cmap='winter')\n",
        "ax.set_title(\"Average Normalized CT\")\n",
        "\n",
        "\n",
        "ax = fig.add_subplot(2, 4, 6, projection='3d')\n",
        "plotting.plot_surf_stat_map(datasets.fetch_surf_fsaverage(mesh='fsaverage').white_left,area_recon,axes=ax,colorbar=True,cmap='winter')\n",
        "ax.set_title(\"Average Reconstructed CT\")\n",
        "ax = fig.add_subplot(2, 4, 7, projection='3d')\n",
        "plotting.plot_surf_stat_map(datasets.fetch_surf_fsaverage(mesh='fsaverage').white_left,func_to_area,axes=ax,colorbar=True,cmap='winter')\n",
        "ax.set_title(\"Average FC -> CT\")\n",
        "\n",
        "ax = fig.add_subplot(2, 4, 8, projection='3d')\n",
        "plotting.plot_surf_stat_map(datasets.fetch_surf_fsaverage(mesh='fsaverage').white_left,thick_to_area,axes=ax,colorbar=True,cmap='winter')\n",
        "ax.set_title(\"Average CSA -> CT\")'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iDiJj11OdB7n"
      },
      "outputs": [],
      "source": [
        "from nilearn import surface\n",
        "texture = surface.vol_to_surf(upscale(data), datasets.fetch_surf_fsaverage(mesh='fsaverage').pial_right)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OeO3msWDZ86F"
      },
      "outputs": [],
      "source": [
        "import plotly\n",
        "\n",
        "plotting.plot_surf_stat_map(datasets.fetch_surf_fsaverage(mesh='fsaverage').pial_left,upscale(data)[:len(data)],\n",
        "                          views=['anterior'],\n",
        "                          hemispheres=['left'],\n",
        "                          colorbar=True)\n",
        "plotting.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ridXrHc7bL2W"
      },
      "outputs": [],
      "source": [
        "\n",
        "stat_img = datasets.load_sample_motor_activation_image()\n",
        "print(stat_img)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "SUBrTu2Vk3gO",
        "kf-WLMrloGpN",
        "o-mpYm7wdJ9u"
      ],
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}